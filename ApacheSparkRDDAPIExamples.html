<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
<!-- saved from url=(0068) -->
<html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><title>Apache Spark RDD API Examples</title>
  <meta name="verify-v1" content="Spark RDD API"></head>
<body>
<div id="_GPL_e6a00_parent_div" style="position: absolute; top: 0px; left: 0px; width: 1px; height: 1px; z-index: 2147483647;">

<table style="width: 100%;" border="0" cellpadding="0" cellspacing="10">
<tbody>
    <tr>
      <td style="width: 1807px;" colspan="3" valign="top">&nbsp;</td>
    </tr>
    <tr>
      <td style="width: 332px;" valign="top">
      </a><h4 style="color:red">Spark RDD API Examples</h4></p>
      <p style="text-align: left;"><span style="font-weight: bold;">RDD
function calls</span><br>
      </p>
      <p style="text-align: left; margin-left: 40px;"><a href="#aggregate">aggregate</a></p>
      <p style="text-align: left; margin-left: 40px;"><a href="#aggregateByKey">aggregateByKey [Pair]<br>
      </a></p>

      <p style="text-align: left; margin-left: 40px;"><a href="#cartesian"><span style="text-decoration: underline;">cartesian</span></a><br>
      </p>
      <p style="text-align: left; margin-left: 40px;"><a href="#checkpoint">checkpoint<br>
      </a></p>
      <p style="text-align: left; margin-left: 40px;"><a href="#coalesce">coalesce, repartition</a></p>
      <p style="text-align: left; margin-left: 40px;"><a href="#cogroup">cogroup
[pair], groupWith [Pair]<br>
      </a></p>
      <p style="text-align: left; margin-left: 40px;"><span style="text-decoration: underline;"></span><a href="#collect">collect,
toArray</a></p>
      <p style="text-align: left; margin-left: 40px;"><a href="#collectAsMap">collectAsMap [pair]</a></p>
      <p style="text-align: left; margin-left: 40px;"><a href="#combineByKey">combineByKey [pair]</a><br>
      </p>
      <p style="text-align: left; margin-left: 40px;"><a href="#compute">compute</a></p>
      <p style="text-align: left; margin-left: 40px;"><a href="#context">context,
sparkContext</a></p>
      <p style="text-align: left; margin-left: 40px;"><a href="#count">count</a></p>
      <p style="text-align: left; margin-left: 40px;"><a href="#countApprox">countApprox</a></p>
      <p style="text-align: left; margin-left: 40px;"><a href="#countApproxDistinct">countApproxDistinct</a></p>

      
      <div style="margin-left: 40px;"><a href="#countApproxDistinceByKey">countApproxDistinctByKey [pair]</a></div>
<p style="text-align: left; margin-left: 40px;"><a href="#countByKey">countByKey [pair]</a></p>
      <p style="text-align: left; margin-left: 40px;"><a href="#countByKeyApprox">countByKeyApprox [pair]<br>
      </a></p>
      <p style="text-align: left; margin-left: 40px;"><a href="#countByValue">countByValue</a></p>
      <p style="text-align: left; margin-left: 40px;"><a href="#countByValueApprox">countByValueApprox</a></p><p style="text-align: left; margin-left: 40px;"><a href="#dependencies">dependencies</a></p>
      <p style="text-align: left; margin-left: 40px;"><a href="#distinct">distinct</a></p>
      <p style="text-align: left; margin-left: 40px;"><a href="#first">first</a></p>
      <p style="text-align: left; margin-left: 40px;"><a href="#filter">filter</a></p>
      <p style="text-align: left; margin-left: 40px;"><a href="#filterByRange">filterByRange [Ordered]<br>
      </a></p>

      <p style="text-align: left; margin-left: 40px;"><a href="#filterWith">filterWith</a></p>
      <p style="text-align: left; margin-left: 40px;"><a href="#flatMap">flatMap</a></p>
      <p style="text-align: left; margin-left: 40px;"><a href="#flatMapValues">flatMapValues [Pair]<br>
      </a></p>
      <p style="text-align: left; margin-left: 40px;"><a href="#flatMapWith">flatMapWith</a></p>
      <p style="text-align: left; margin-left: 40px;"><a href="#fold">fold</a></p>
      <p style="text-align: left; margin-left: 40px;"><a href="#foldByKey">foldByKey [Pair]<br>
      </a></p>
      <p style="text-align: left; margin-left: 40px;"><a href="#foreach">foreach</a></p>
      <p style="text-align: left; margin-left: 40px;"><a href="#foreachPartition">foreachPartition</a></p>
      <p style="text-align: left; margin-left: 40px;"><a href="#foreachWith">foreachWith</a></p>
      <p style="text-align: left; margin-left: 40px;"><a href="#fullOuterJoin">fullOuterJoin [Pair]<br>
      </a></p>

      <p style="text-align: left; margin-left: 40px;"><a href="#generator">generator, setGenerator</a></p>
      <p style="text-align: left; margin-left: 40px;"><a href="#getCheckpointFile">getCheckpointFile</a></p>
      <p style="text-align: left; margin-left: 40px;"><a href="#preferredLocations">preferredLocations</a></p>
      <p style="text-align: left; margin-left: 40px;"><a href="#getStorageLevel">getStorageLevel</a></p>
      <p style="text-align: left; margin-left: 40px;"><a href="#glom">glom</a></p>
      <p style="text-align: left; margin-left: 40px;"><a href="#groupBy">groupBy</a></p>
      <p style="text-align: left; margin-left: 40px;"><a href="#groupByKey">groupByKey [Pair]</a></p>
      <p style="text-align: left; margin-left: 40px;"><a href="#histogram">histogram [Double]<br>
      </a></p>
      <p style="text-align: left; margin-left: 40px;"><a href="#id">id</a></p>
      <p style="text-align: left; margin-left: 40px;"><a href="#intersection">intersection<br>
      </a></p>
      <p style="text-align: left; margin-left: 40px;"><a href="#isCheckpointed">isCheckpointed</a></p>
      <p style="text-align: left; margin-left: 40px;"><a href="#iterator">iterator</a></p>
      <p style="text-align: left; margin-left: 40px;"><a href="#join">join
[pair]<br>
      </a></p>
      <p style="text-align: left; margin-left: 40px;"><a href="#keyBy">keyBy</a></p>
      <p style="text-align: left; margin-left: 40px;"><a href="#keys">keys
[pair]</a></p>
      <p style="text-align: left; margin-left: 40px;"><a href="#leftOuterJoin">leftOuterJoin [pair]</a></p>
      <p style="text-align: left; margin-left: 40px;"><a href="#lookup">lookup
[pair]<br>
      </a></p>
      <p style="text-align: left; margin-left: 40px;"><span style="text-decoration: underline;"></span><a href="#map">map</a></p>
      <p style="text-align: left; margin-left: 40px;"><a href="#mapPartitions">mapPartitions</a></p>
      <p style="text-align: left; margin-left: 40px;"><a href="#mapPartitionsWithContext">mapPartitionsWithContext</a></p>
      <p style="text-align: left; margin-left: 40px;"><a href="#mapPartitionsWithIndex">mapPartitionsWithIndex</a></p>
      <p style="text-align: left; margin-left: 40px;"><a href="#mapPartitionsWithSplit">mapPartitionsWithSplit</a></p>
      <p style="text-align: left; margin-left: 40px;"><a href="#mapValues">mapValues [pair]</a><br>
      </p>
      <p style="text-align: left; margin-left: 40px;"><a href="#mapWith">mapWith</a></p>
      <p style="text-align: left; margin-left: 40px;"><a href="#max">max</a></p>
      <p style="text-align: left; margin-left: 40px;"><a href="#mean">mean
[Double], meanApprox [Double]</a></p>
      <p style="text-align: left; margin-left: 40px;"><a href="#min">min</a><br>
      </p>
      <p style="text-align: left; margin-left: 40px;"><a href="#name">name,
setName</a></p>
      <p style="text-align: left; margin-left: 40px;"><a href="#partitionBy">partitionBy [Pair]</a><br>
      </p>
      <p style="text-align: left; margin-left: 40px;"><a href="#partitioner">partitioner</a></p>
      <p style="text-align: left; margin-left: 40px;"><a href="#partitions">partitions</a></p>
      <p style="text-align: left; margin-left: 40px;"><a href="#persist">persist,
cache</a></p>
      <p style="text-align: left; margin-left: 40px;"><a href="#pipe">pipe</a></p>
      <p style="text-align: left; margin-left: 40px;"><a href="#randomSplit">randomSplit<br>
      </a></p>
      <p style="text-align: left; margin-left: 40px;"><a href="#reduce">reduce</a></p>
      <p style="text-align: left; margin-left: 40px;"><a href="#reduceByKey">reduceByKey [Pair], reduceByKeyLocally[Pair],
reduceByKeyToDriver[Pair]</a></p>
      <p style="text-align: left; margin-left: 40px;"><a href="#repartition">repartition</a></p>
      <p style="text-align: left; margin-left: 40px;"><a href="#repartitionAndSortWithinPartitions">repartitionAndSortWithPartitions [Ordered]<br>
      </a></p>


      <p style="text-align: left; margin-left: 40px;"><a href="#rightOuterJoin">rightOuterJoin [Pair] </a><br>
      </p>
      <p style="text-align: left; margin-left: 40px;"><a href="#sample">sample</a></p>
      <p style="text-align: left; margin-left: 40px;"><a href="#sampleByKey">sampleByKey [Pair]</a></p>
      <p style="text-align: left; margin-left: 40px;"><a href="#sampleByKeyExact">sampleByKeyExact [Pair]<br>
      </a></p>

      <p style="text-align: left; margin-left: 40px;"><a href="#saveAsHadoopFile">saveAsHodoopFile [Pair], saveAsHadoopDataset
[Pair], saveAsNewAPIHadoopFile [Pair]</a><br>
      </p>
      <p style="text-align: left; margin-left: 40px;"><a href="#saveAsObjectFile">saveAsObjectFile</a></p>
      <p style="text-align: left; margin-left: 40px;"><a href="#saveAsSequenceFile">saveAsSequenceFile [SeqFile]<br>
      </a></p>
      <p style="text-align: left; margin-left: 40px;"><a href="#saveAsTextFile">saveAsTextFile</a></p>
      <p style="text-align: left; margin-left: 40px;"><a href="#stats">stats
[Double]</a></p>
      <p style="text-align: left; margin-left: 40px;"><a href="#sortBy">sortBy<br>
      </a></p>
      <p style="text-align: left; margin-left: 40px;"><a href="#sortByKey">sortByKey [Ordered]</a></p>
      <p style="text-align: left; margin-left: 40px;"><a href="#stdev">stdev
[Double], sampleStdev [Double]</a></p>
      <p style="text-align: left; margin-left: 40px;"><a href="#subtract">subtract<br>
      </a></p>
      <p style="text-align: left; margin-left: 40px;"><a href="#subtractByKey">subtractByKey [Pair]</a></p>
      <p style="text-align: left; margin-left: 40px;"><a href="#sum">sum
[Double], sumApprox[Double]</a><br>
      </p>
      <p style="text-align: left; margin-left: 40px;"><a href="#take">take</a></p>
      <p style="text-align: left; margin-left: 40px;"><a href="#takeOrdered">takeOrdered</a></p>
      <p style="text-align: left; margin-left: 40px;"><a href="#takeSample">takeSample</a></p>
      <p style="text-align: left; margin-left: 40px;"><a href="#treeAggregate">treeAggregate</a></p>
      <p style="text-align: left; margin-left: 40px;"><a href="#treeReduce">treeReduce<br>
      </a></p>

      <p style="text-align: left; margin-left: 40px;"><a href="#toDebugString">toDebugString</a></p>
      <p style="text-align: left; margin-left: 40px;"><a href="#toJavaRDD">toJavaRDD</a></p>
      <p style="text-align: left; margin-left: 40px;"><a href="#toLocalIterator">toLocalIterator<br>
</a></p>
      <p style="text-align: left; margin-left: 40px;"><a href="#top">top</a></p>

      <p style="text-align: left; margin-left: 40px;"><a href="#toString">toString</a></p>
      <p style="text-align: left; margin-left: 40px;"><a href="#union">union,
++</a></p>
      <p style="text-align: left; margin-left: 40px;"><a href="#unpersist">unpersist</a></p>
      <p style="text-align: left; margin-left: 40px;"><a href="#values">values
[Pair]</a></p>
      <p style="text-align: left; margin-left: 40px;"><a href="#variance">variance [Double], sampleVariance [Double]</a><br>
      </p>
      <p style="text-align: left; margin-left: 40px;"><a href="#zip">zip</a></p>
      <p style="text-align: left; margin-left: 40px;"><a href="#zipPartitions">zipPartitions</a></p>
      <p style="text-align: left; margin-left: 40px;"><a href="#zipWithIndex">zipWithIndex</a></p>
      <p style="text-align: left; margin-left: 40px;"><a href="#zipWithUniqueId">zipWithUniquId<br>
      </a></p>
      <p style="text-align: left; margin-left: 40px;"><br>
      </p>
      <br>
      <p style="text-align: left; margin-left: 40px;"><br>
      </p>
      <br>
      <p style="text-align: left; margin-left: 40px;"><br>
      </p>
      <p style="text-align: left; margin-left: 40px;"><br>
      </p>
      <p style="text-align: left; margin-left: 40px;"><a href="http://homepage.cs.latrobe.edu.au/zhe/Zhen%20He.html#talks"><br>
      </a></p>
      <p style="text-align: left; margin-left: 40px;"><a href="http://homepage.cs.latrobe.edu.au/zhe/Zhen%20He.html#talks"><br>
      </a></p>
      <p style="text-align: left; margin-left: 40px;"><span style="text-decoration: underline;"></span><br>
      </p>
      <p> </p>
      </td>
      <td style="vertical-align: top; width: 0px;"><br>
      </td>
      <td style="width: 1807px; vertical-align: top;"> <br>
      <br>
Our research group has a very strong focus on using and improving
Apache Spark to solve real world programs. In order to do this we need
to have a very solid understanding of the capabilities of Spark. So one
of the first things we have done is to go through the entire Spark RDD
API and write examples to test their functionality. This has been a
very useful exercise and we would like to share the examples with
everyone.<br>
      <br>
Authors of examples: Zhang Zi Kuo<br>
Emails addresses: zhangzikuo@126.com<br>
      <br>
These examples have only been tested for Spark version 1.4. We assume
the functionality of Spark is stable and therefore the examples should
be valid for later releases.<br>
      <br>
If you find any errors in the example we would love to hear about them so we can fix them up. So please email us to let us know.<br>
      <br>
      <br>
      <big><span style="font-weight: bold;">The RDD API By Example</span></big><br>
      <br>
      <p class="p9 ft4">RDD is short for Resilient Distributed Dataset.
RDDs
are the workhorse of the Spark system. As a user, one can consider a
RDD as a handle for a collection of individual data partitions, which
are the result of some computation.</p>
      <p class="p22 ft4">However, an RDD is actually more than that. On
cluster installations, separate data partitions can be on separate
nodes. Using the RDD as a handle one can access all partitions and
perform computations and transformations using the contained data.
Whenever a part of a RDD or an entire RDD is lost, the system is able
to reconstruct the data of lost partitions by using lineage
information. Lineage refers to the sequence of transformations used to
produce the current RDD. As a result, Spark is able to recover
automatically from most failures.</p>
      <p class="p23 ft8">All RDDs available in Spark derive either
directly
or indirectly from the class RDD. This class comes with a large set of
methods that perform operations on the data within the associated
partitions. The class RDD is abstract. Whenever, one uses a RDD, one is
actually using a concertized implementation of RDD. These
implementations have to overwrite some core functions to make the RDD
behave as expected.</p>
      <p class="p24 ft4">One reason why Spark has lately become a very
popular system for processing big data is that it does not impose
restrictions regarding what data can be stored within RDD partitions.
The RDD API already contains many useful operations. But, because the
creators of Spark had to keep the core API of RDDs common enough to
handle arbitrary <nobr>data-types,</nobr> many convenience functions
are missing.</p>
      <p class="p10 ft4">The basic RDD API considers each data item as
a single value. However, users often want to work with <nobr>key-value</nobr>
pairs. Therefore Spark extended the interface of RDD to provide
additional functions (PairRDDFunctions), which explicitly work on <nobr>key-value</nobr>
pairs. Currently, there are four extensions to the RDD API available in
spark. They are as follows:</p>
      <p class="p25 ft4">DoubleRDDFunctions <br>
      </p>
      <div style="margin-left: 40px;">This extension contains many
useful methods for aggregating numeric values. They become available if
the data items of an RDD are implicitly convertible to the Scala <nobr>data-type</nobr>
double.</div>
      <p class="p26 ft4">PairRDDFunctions <br>
      </p>
      <p style="margin-left: 40px;" class="p26 ft4">Methods defined in
this interface
extension become available when the data items have a two component
tuple structure. Spark will interpret the first tuple item (i.e.
tuplename. 1) as the key and the second item (i.e. tuplename. 2) as the
associated value.</p>
      <p class="p27 ft4">OrderedRDDFunctions <br>
      </p>
      <p style="margin-left: 40px;" class="p27 ft4">Methods defined in
this interface
extension become available if the data items are two-component tuples
where the key is implicitly sortable.</p>
      <p class="p28 ft9">SequenceFileRDDFunctions <br>
      </p>
      <p style="margin-left: 40px;" class="p29 ft4">This extension
contains
several methods that allow users to create Hadoop sequence- les from
RDDs. The data items must be two compo- nent <nobr>key-value</nobr>
tuples as required by the PairRDDFunctions. However, there are
additional requirements considering the convertibility of the tuple
components to Writable types.</p>
      <p class="p30 ft4">Since Spark will make methods with extended
functionality automatically available to users when the data items
fulfill the above described requirements, we decided to list all
possible
available functions in strictly alphabetical order. We will append
either of the followingto the <nobr>function-name</nobr> to indicate
it belongs to an extension that requires the data items to conform to a
certain format or type.</p>
      <p class="p30 ft4"> <span class="ft10">[Double] </span>- Double
RDD Functions<br>
      </p>
      <p class="p30 ft4"> <span class="ft10">[Ordered]</span> -
OrderedRDDFunctions<br>
      </p>
      <p class="p30 ft4"> <span class="ft10">[Pair] - PairRDDFunctions<br>
      </span></p>
      <p class="p30 ft4"><span class="ft10"></span><span class="ft10">[SeqFile]</span>
- SequenceFileRDDFunctions</p>
      <p class="p30 ft4"><br>
      </p>
      <hr style="width: 100%; height: 2px;"> <big><big><span style="font-weight: bold;"><br>
      <a name="aggregate"></a><br>
aggregate</span></big></big><br>
      <br>
The <span style="font-weight: bold;">aggregate</span> function allows the user to apply <span style="font-weight: bold;">two</span>
different reduce functions to the RDD. The first reduce function is
applied within each partition to reduce the data within each partition
into a single result. The second reduce function is used to combine the
different reduced results of all partitions together to arrive at one
final result. The ability to have two separate reduce functions for
intra partition versus across partition reducing adds a lot of
flexibility. For example the first reduce function can be the max
function and the second one can be the sum function. The user also
specifies an initial value. Here are some important facts.<ul><li>The initial value is applied at both levels of reduce. So both at the intra partition reduction and across partition reduction.<br>
</li>
        <li>Both reduce functions have to be commutative and
associative.</li>

        
        
        <li>Do not assume any execution order for either partition
computations or combining partitions.</li>
        <li>Why would one want to use two input data types? Let us
assume we do an archaeological site survey using a metal detector.
While walking through the site we take GPS coordinates of important
findings based on the output of the metal detector. Later, we intend to
draw an image of a map that highlights these locations using the <span style="font-weight: bold;">aggregate </span>function. In this case
the <span style="font-weight: bold;">zeroValue</span>
could be an area map with no highlights. The possibly huge set of input
data is stored as GPS coordinates across many partitions. <span style="font-weight: bold;">seqOp (first reducer)</span> could convert the GPS
coordinates to map coordinates and put a marker on the map at the
respective position. <span style="font-weight: bold;">combOp (second reducer) </span>will
receive these highlights as partial maps and combine them into a single
final output map.</li>

      </ul>
      <span style="font-weight: bold;">Listing Variants</span><br>
      <br>
      <div style="margin-left: 40px;">def aggregate[U:
ClassTag](zeroValue: U)(seqOp: (U, T) =&gt; U, combOp: (U, U) =&gt; U):
U<br>
      </div>
      <br>
      <p style="font-weight: bold;" class="p30 ft4">Examples 1</p>
      <div style="margin-left: 40px;">
      <table style="text-align: left; width: 559px; height: 340px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top; background-color: rgb(242, 242, 242);">val
z = sc.parallelize(List(1,2,3,4,5,6), 2)<br>
            <br>
// lets first print out the contents of the RDD with partition labels<br>
def myfunc(index: Int, iter: Iterator[(Int)]) : Iterator[String] = {<br>
&nbsp; iter.map(x =&gt; "[partID:" +&nbsp; index + ", val: " + x + "]")<br>
}<br>
            <br>
z.mapPartitionsWithIndex(myfunc).collect<br>
res28: Array[String] = Array([partID:0, val: 1], [partID:0, val: 2],
[partID:0, val: 3], [partID:1, val: 4], [partID:1, val: 5], [partID:1,
val: 6])<br>
<br>
z.aggregate(0)(math.max(_, _), _ + _)<br>
res40: Int = 9<br>
            <br>
// This example returns 16 since the initial value is 5<br>
// reduce of partition 0 will be max(5, 1, 2, 3) = 5<br>
// reduce of partition 1 will be max(5, 4, 5, 6) = 6<br>
// final reduce across partitions will be 5 + 5 + 6 = 16<br>
// note the final reduce include the initial value<br>

z.aggregate(5)(math.max(_, _), _ + _)<br>
res29: Int = 16<br>
<br>
            <br>
val z = sc.parallelize(List("a","b","c","d","e","f"),2)<br>
            <br>
//lets first print out the contents of the RDD with partition labels<br>

def myfunc(index: Int, iter: Iterator[(String)]) : Iterator[String] = {<br>

&nbsp; iter.map(x =&gt; "[partID:" +&nbsp; index + ", val: " + x + "]")<br>

}<br>

            <br>

z.mapPartitionsWithIndex(myfunc).collect<br>

res31: Array[String] = Array([partID:0, val: a], [partID:0, val: b],
[partID:0, val: c], [partID:1, val: d], [partID:1, val: e], [partID:1,
val: f])<br>
            <br>
z.aggregate("")(_ + _, _+_)<br>
res115: String = abcdef<br>
            <br>
// See here how the initial value "x" is applied three times.<br>
//&nbsp; - once for each partition<br>
//&nbsp; - once when combining all the partitions in the second reduce function.<br>
z.aggregate("x")(_ + _, _+_)<br>
res116: String = xxdefxabc<br>
            <br>
// Below are some more advanced examples. Some are quite tricky to work out.<br>
<br>
val z = sc.parallelize(List("12","23","345","4567"),2)<br>
z.aggregate("")((x,y) =&gt; math.max(x.length, y.length).toString,
(x,y) =&gt; x + y)<br>
res141: String = 42<br>
            <br>
z.aggregate("")((x,y) =&gt; math.min(x.length, y.length).toString,
(x,y) =&gt; x + y)<br>
res142: String = 11<br>
            <br>
val z = sc.parallelize(List("12","23","345",""),2)<br>
z.aggregate("")((x,y) =&gt; math.min(x.length, y.length).toString,
(x,y) =&gt; x + y)<br>
res143: String = 10</td>
          </tr>
        </tbody>
      </table>
      </div>
      <span style="font-weight: bold;"><br>
      </span>The main issue with the code above is that the result of
the inner <span style="font-weight: bold;">min</span> is a string of
length 1. <br>
The zero in the output is due to the empty string being the last string
in the list. We see this result because we are not recursively reducing
any further within the partition for the final string.<br>
      <br>
      <span style="font-weight: bold;">Examples 2</span><br>
      <br>
      <div style="margin-left: 40px;"><span style="font-weight: bold;"></span><br>
      <table style="text-align: left; width: 519px; height: 71px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top; background-color: rgb(242, 242, 242);">val
z = sc.parallelize(List("12","23","","345"),2)<br>
z.aggregate("")((x,y) =&gt; math.min(x.length, y.length).toString,
(x,y) =&gt; x + y)<br>
res144: String = 11</td>
          </tr>
        </tbody>
      </table>
      <br>
      </div>
In contrast to the previous example, this example has the empty string
at the beginning of the second partition. This results in length of
zero being input to the second reduce which then upgrades it a length
of 1. <span style="font-style: italic;">(Warning: The above example
shows bad design since the output is dependent on the order of the data
inside the partitions.)</span><br>
      <br>
      <hr style="width: 100%; height: 2px;"><br>
      <a name="aggregateByKey"></a><br>
      <br>
      <big><big><span style="font-weight: bold;">aggregateByKey</span></big></big> [Pair]<br>

      <br>

      
      <div style="text-align: left; width: 1799px;">Works like the
aggregate function except the aggregation is applied to the values with
the same key. Also unlike the aggregate function the initial value is
not applied to the second reduce.<br>
      </div>

      
      <div style="margin-left: 40px;"><span style="font-weight: bold;"><br>
      </span></div>

      <span style="font-weight: bold;">Listing Variants</span><br>

      
      <div style="margin-left: 40px;"><br>
      </div>

      
      <div style="margin-left: 40px;">def aggregateByKey[U](zeroValue: U)(seqOp: (U, V) &#8658; U, combOp: (U, U) &#8658; U)(implicit arg0: ClassTag[U]): RDD[(K, U)]<br>
def aggregateByKey[U](zeroValue: U, numPartitions: Int)(seqOp: (U, V) &#8658;
U, combOp: (U, U) &#8658; U)(implicit arg0: ClassTag[U]): RDD[(K, U)]<br>
def aggregateByKey[U](zeroValue: U, partitioner: Partitioner)(seqOp:
(U, V) &#8658; U, combOp: (U, U) &#8658; U)(implicit arg0: ClassTag[U]): RDD[(K, U)]<br>
      </div>

      <br>
      <br>
      <span style="font-weight: bold;">Example</span><br>
      <br>
      <table style="text-align: left; width: 584px; margin-left: 40px; height: 25px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top;">val pairRDD = sc.parallelize(List( ("cat",2), ("cat", 5), ("mouse", 4),("cat", 12), ("dog", 12), ("mouse", 2)), 2)<br>
            <br>
// lets have a look at what is in the partitions<br>
def myfunc(index: Int, iter: Iterator[(String, Int)]) : Iterator[String] = {<br>
&nbsp; iter.map(x =&gt; "[partID:" +&nbsp; index + ", val: " + x + "]")<br>
}<br>
pairRDD.mapPartitionsWithIndex(myfunc).collect<br>
            <br>
res2: Array[String] = Array([partID:0, val: (cat,2)], [partID:0, val:
(cat,5)], [partID:0, val: (mouse,4)], [partID:1, val: (cat,12)],
[partID:1, val: (dog,12)], [partID:1, val: (mouse,2)])<br>
            <br>
pairRDD.aggregateByKey(0)(math.max(_, _), _ + _).collect<br>
res3: Array[(String, Int)] = Array((dog,12), (cat,17), (mouse,6))<br>
            <br>
pairRDD.aggregateByKey(100)(math.max(_, _), _ + _).collect<br>
res4: Array[(String, Int)] = Array((dog,100), (cat,200), (mouse,200))<br>
            <br>
            </td>
          </tr>
        </tbody>
      </table>
      <br>
<br>
      <hr style="width: 100%; height: 2px;"><br>
      <big><big><a name="cartesian"></a><br style="font-weight: bold;">
      <span style="font-weight: bold;">cartesian</span></big></big><br>
      <br>
      <div style="text-align: left;">Computes the cartesian product
between two RDDs (i.e. Each item of the first RDD is joined with each
item of the second RDD) and returns them as a new RDD. <span style="font-style: italic;">(Warning: Be careful when using this
function.! Memory consumption can quickly become an issue!)</span><br>
      </div>
      <div style="margin-left: 40px;"><span style="font-weight: bold;"><br>
      </span></div>
      <span style="font-weight: bold;">Listing Variants</span><br>
      <div style="margin-left: 40px;"><br>
      </div>
      <div style="margin-left: 40px;">def cartesian[U: ClassTag](other:
RDD[U]): RDD[(T, U)]<br>
      </div>
      <br>
      <span style="font-weight: bold;">Example</span><br>
      <div style="margin-left: 40px;"><span style="font-weight: bold;"></span><br>
      <table style="text-align: left; width: 522px; height: 108px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top; background-color: rgb(242, 242, 242);">val
x = sc.parallelize(List(1,2,3,4,5))<br>
val y = sc.parallelize(List(6,7,8,9,10))<br>
x.cartesian(y).collect<br>
res0: Array[(Int, Int)] = Array((1,6), (1,7), (1,8), (1,9), (1,10),
(2,6), (2,7), (2,8), (2,9), (2,10), (3,6), (3,7), (3,8), (3,9), (3,10),
(4,6), (5,6), (4,7), (5,7), (4,8), (5,8), (4,9), (4,10), (5,9), (5,10))</td>
          </tr>
        </tbody>
      </table>
      <br>
      </div>
      <br>
      <br>
      <hr style="width: 100%; height: 2px;"><br>
      <a name="checkpoint"></a><br>
      <br>
      <big style="font-weight: bold;"><big>checkpoint</big></big><br>
      <br>
Will create a checkpoint when the RDD is computed next. Checkpointed
RDDs are stored as a binary file within the checkpoint directory which
can be specified using the Spark context.<span style="font-style: italic;"> (Warning: Spark applies lazy evaluation.
Checkpointing will not occur until an action is invoked.)</span><br>
      <br>
Important note: the directory&nbsp; "my_directory_name" should exist in
all slaves. As an alternative you could use an HDFS directory URL as
well.<br>
      <br>
      <span style="font-weight: bold;">Listing Variants</span><br>
      <div style="margin-left: 40px;"><br>
      </div>
      <div style="margin-left: 40px;">def checkpoint()<br>
      </div>
      <br>
      <span style="font-weight: bold;">Example</span><br>
      <div style="margin-left: 40px;"><span style="font-weight: bold;"></span><br>
      <table style="text-align: left; width: 522px; height: 108px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top; background-color: rgb(242, 242, 242);">sc.setCheckpointDir("my_directory_name")<br>
val a = sc.parallelize(1 to 4)<br>
a.checkpoint<br>
a.count<br>
14/02/25 18:13:53 INFO SparkContext: Starting job: count at
&lt;console&gt;:15<br>
...<br>
14/02/25 18:13:53 INFO MemoryStore: Block broadcast_5 stored as values
to memory (estimated size 115.7 KB, free 296.3 MB)<br>
14/02/25 18:13:53 INFO RDDCheckpointData: Done checkpointing RDD 11 to
file:/home/cloudera/Documents/spark-0.9.0-incubating-bin-cdh4/bin/my_directory_name/65407913-fdc6-4ec1-82c9-48a1656b95d6/rdd-11,
new parent is RDD 12<br>
res23: Long = 4</td>
          </tr>
        </tbody>
      </table>
      </div>
      <br>
      <br>
      <hr style="width: 100%; height: 2px;">
      <p class="p30 ft4"><big><big><span style="font-weight: bold;"><a name="coalesce"></a><br>
      </span></big></big></p>
      <p class="p30 ft4"><big><big><span style="font-weight: bold;">coalesce,
repartition</span></big></big><br>
      <br>
      </p>
      <div style="text-align: left;">Coalesces the associated data into
a given number of partitions. <span style="font-style: italic;">repartition(numPartitions)</span>
is simply an abbreviation for <span style="font-style: italic;">coalesce(numPartitions,
shuffle = true)</span>.<br>
      </div>
      <div style="margin-left: 40px;"><span style="font-weight: bold;"><br>
      </span></div>
      <span style="font-weight: bold;">Listing Variants</span><br>
      <br>
      <div style="margin-left: 40px;">def coalesce ( numPartitions :
Int , shuffle : Boolean = false ): RDD [T]<br>
def repartition ( numPartitions : Int ): RDD [T] </div>
      <br>
      <span style="font-weight: bold;">Example</span><br>
      <br>
      <div style="margin-left: 40px;">
      <table style="text-align: left; width: 522px; height: 108px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top; background-color: rgb(242, 242, 242);">val
y = sc.parallelize(1 to 10, 10)<br>
val z = y.coalesce(2, false)<br>
z.partitions.length<br>
res9: Int = 2</td>
          </tr>
        </tbody>
      </table>
      </div>
      <br>
      <br>
      <hr style="width: 100%; height: 2px;"><br>
      <a name="cogroup"></a><br>
      <p class="p30 ft4"><big><big><span style="font-weight: bold;">cogroup
      <small>[Pair]</small>, groupWith <small>[Pair]</small></span></big></big><br>
      <br>
      </p>
      <div style="text-align: left;">A very powerful set of functions
that allow grouping up to 3 key-value RDDs together using their keys.<br>
      </div>
      <div style="margin-left: 40px;"><span style="font-weight: bold;"><br>
      </span></div>
      <span style="font-weight: bold;">Listing Variants</span><br>
      <br>
      <div style="margin-left: 40px;">def cogroup[W](other: RDD[(K,
W)]): RDD[(K, (Iterable[V], Iterable[W]))]<br>
def cogroup[W](other: RDD[(K, W)], numPartitions: Int): RDD[(K,
(Iterable[V], Iterable[W]))]<br>
def cogroup[W](other: RDD[(K, W)], partitioner: Partitioner): RDD[(K,
(Iterable[V], Iterable[W]))]<br>
def cogroup[W1, W2](other1: RDD[(K, W1)], other2: RDD[(K, W2)]):
RDD[(K, (Iterable[V], Iterable[W1], Iterable[W2]))]<br>
def cogroup[W1, W2](other1: RDD[(K, W1)], other2: RDD[(K, W2)],
numPartitions: Int): RDD[(K, (Iterable[V], Iterable[W1], Iterable[W2]))]<br>
def cogroup[W1, W2](other1: RDD[(K, W1)], other2: RDD[(K, W2)],
partitioner: Partitioner): RDD[(K, (Iterable[V], Iterable[W1],
Iterable[W2]))]<br>
def groupWith[W](other: RDD[(K, W)]): RDD[(K, (Iterable[V],
Iterable[W]))]<br>
def groupWith[W1, W2](other1: RDD[(K, W1)], other2: RDD[(K, W2)]):
RDD[(K, (Iterable[V], IterableW1], Iterable[W2]))] </div>
      <br>
      <span style="font-weight: bold;">Example</span>s<br>
      <br>
      <div style="margin-left: 40px;">
      <table style="text-align: left; width: 522px; height: 108px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top; background-color: rgb(242, 242, 242);">val
a = sc.parallelize(List(1, 2, 1, 3), 1)<br>
val b = a.map((_, "b"))<br>
val c = a.map((_, "c"))<br>
b.cogroup(c).collect<br>
res7: Array[(Int, (Iterable[String], Iterable[String]))] = Array(<br>
(2,(ArrayBuffer(b),ArrayBuffer(c))),<br>
(3,(ArrayBuffer(b),ArrayBuffer(c))),<br>
(1,(ArrayBuffer(b, b),ArrayBuffer(c, c)))<br>
)<br>
            <br>
val d = a.map((_, "d"))<br>
b.cogroup(c, d).collect<br>
res9: Array[(Int, (Iterable[String], Iterable[String],
Iterable[String]))] = Array(<br>
(2,(ArrayBuffer(b),ArrayBuffer(c),ArrayBuffer(d))),<br>
(3,(ArrayBuffer(b),ArrayBuffer(c),ArrayBuffer(d))),<br>
(1,(ArrayBuffer(b, b),ArrayBuffer(c, c),ArrayBuffer(d, d)))<br>
)<br>
            <br>
val x = sc.parallelize(List((1, "apple"), (2, "banana"), (3, "orange"),
(4, "kiwi")), 2)<br>
val y = sc.parallelize(List((5, "computer"), (1, "laptop"), (1,
"desktop"), (4, "iPad")), 2)<br>
x.cogroup(y).collect<br>
res23: Array[(Int, (Iterable[String], Iterable[String]))] = Array(<br>
(4,(ArrayBuffer(kiwi),ArrayBuffer(iPad))), <br>
(2,(ArrayBuffer(banana),ArrayBuffer())), <br>
(3,(ArrayBuffer(orange),ArrayBuffer())),<br>
(1,(ArrayBuffer(apple),ArrayBuffer(laptop, desktop))),<br>
(5,(ArrayBuffer(),ArrayBuffer(computer))))</td>
          </tr>
        </tbody>
      </table>
      </div>
      <br>
      <br>
      <hr style="width: 100%; height: 2px;"><br>
      <a name="collect"></a><br>
      <p class="p30 ft4"><big><big><span style="font-weight: bold;">collect,
toArray</span></big></big><br>
      <br>
      </p>
      <div style="text-align: left;">Converts the RDD into a Scala
array and returns it. If you provide a standard map-function (i.e. f =
T -&gt; U) it will be applied before inserting the values into the
result array.<br>
      </div>
      <div style="margin-left: 40px;"><span style="font-weight: bold;"><br>
      </span></div>
      <span style="font-weight: bold;">Listing Variants</span><br>
      <br>
      <div style="margin-left: 40px;">def collect(): Array[T]<br>
def collect[U: ClassTag](f: PartialFunction[T, U]): RDD[U]<br>
def toArray(): Array[T] </div>
      <br>
      <span style="font-weight: bold;">Example</span><br>
      <br>
      <div style="margin-left: 40px;">
      <table style="text-align: left; width: 522px; height: 62px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top; background-color: rgb(242, 242, 242);">val
c = sc.parallelize(List("Gnu", "Cat", "Rat", "Dog", "Gnu", "Rat"), 2)<br>
c.collect<br>
res29: Array[String] = Array(Gnu, Cat, Rat, Dog, Gnu, Rat)</td>
          </tr>
        </tbody>
      </table>
      </div>
      <br>
      <br>
      <hr style="width: 100%; height: 2px;"><br>
      <a name="collectAsMap"></a><br>
      <p class="p30 ft4"><big><big><span style="font-weight: bold;">collectAsMap
      <small>[Pair]</small> </span></big></big><br>
      <br>
      </p>
      <div style="text-align: left;">Similar to <span style="font-style: italic;">collect</span>, but works on key-value
RDDs and converts them into Scala maps to preserve their key-value
structure.<br>
      </div>
      <div style="margin-left: 40px;"><span style="font-weight: bold;"><br>
      </span></div>
      <span style="font-weight: bold;">Listing Variants</span><br>
      <br>
      <div style="margin-left: 40px;">def collectAsMap(): Map[K, V] </div>
      <br>
      <span style="font-weight: bold;">Example</span><br>
      <br>
      <div style="margin-left: 40px;">
      <table style="text-align: left; width: 522px; height: 62px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top; background-color: rgb(242, 242, 242);">val
a = sc.parallelize(List(1, 2, 1, 3), 1)<br>
val b = a.zip(a)<br>
b.collectAsMap<br>
res1: scala.collection.Map[Int,Int] = Map(2 -&gt; 2, 1 -&gt; 1, 3 -&gt;
3)</td>
          </tr>
        </tbody>
      </table>
      </div>
      <br>
      <br>
      <hr style="width: 100%; height: 2px;"><br>
      <a name="combineByKey"></a><br>
      <p class="p30 ft4"><big><big><span style="font-weight: bold;">combineByKey[Pair]
      </span></big></big><br>
      <br>
      </p>
      <div style="text-align: left;">Very efficient implementation that
combines the values of a RDD consisting of two-component tuples by
applying multiple aggregators one after another.<br>
      </div>
      <div style="margin-left: 40px;"><span style="font-weight: bold;"><br>
      </span></div>
      <span style="font-weight: bold;">Listing Variants</span><br>
      <div style="margin-left: 40px;">def
combineByKey[C](createCombiner: V =&gt; C, mergeValue: (C, V) =&gt; C,
mergeCombiners: (C, C) =&gt; C): RDD[(K, C)]<br>
def combineByKey[C](createCombiner: V =&gt; C, mergeValue: (C, V) =&gt;
C, mergeCombiners: (C, C) =&gt; C, numPartitions: Int): RDD[(K, C)]<br>
def combineByKey[C](createCombiner: V =&gt; C, mergeValue: (C, V) =&gt;
C, mergeCombiners: (C, C) =&gt; C, partitioner: Partitioner,
mapSideCombine: Boolean = true, serializerClass: String = null):
RDD[(K, C)] </div>
      <br>
      <span style="font-weight: bold;">Example</span><br>
      <br>
      <div style="margin-left: 40px;">
      <table style="text-align: left; width: 586px; height: 153px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top; background-color: rgb(242, 242, 242);">val
a =
sc.parallelize(List("dog","cat","gnu","salmon","rabbit","turkey","wolf","bear","bee"),
3)<br>
val b = sc.parallelize(List(1,1,2,2,2,1,2,2,2), 3)<br>
val c = b.zip(a)<br>
val d = c.combineByKey(List(_), (x:List[String], y:String) =&gt; y ::
x, (x:List[String], y:List[String]) =&gt; x ::: y)<br>
d.collect<br>
res16: Array[(Int, List[String])] = Array((1,List(cat, dog, turkey)),
(2,List(gnu, rabbit, salmon, bee, bear, wolf)))</td>
          </tr>
        </tbody>
      </table>
      </div>
      <br>
      <br>
      <hr style="width: 100%; height: 2px;"><br>
      <a name="compute"></a><br>
      <p class="p30 ft4"><big><big><span style="font-weight: bold;">compute</span></big></big><br>
      </p>
      <div style="text-align: left;">Executes dependencies and computes
the actual representation of the RDD. This function should not be
called directly by users.<br>
      </div>
      <div style="margin-left: 40px;"><span style="font-weight: bold;"><br>
      </span></div>
      <span style="font-weight: bold;">Listing Variants</span><br>
      <br>
      <div style="margin-left: 40px;">def compute(split: Partition,
context: TaskContext): Iterator[T] </div>
      <br>
      <hr style="width: 100%; height: 2px;">
      <p class="p30 ft4"><big><big><span style="font-weight: bold;"><a name="context"></a></span></big></big></p>
      <p class="p30 ft4"><big><big><span style="font-weight: bold;">context,
sparkContext</span></big></big><br>
      </p>
      <div style="text-align: left;">Returns the <span style="font-style: italic;">SparkContext</span> that was used to
create the RDD.<br>
      </div>
      <div style="margin-left: 40px;"><span style="font-weight: bold;"><br>
      </span></div>
      <span style="font-weight: bold;">Listing Variants</span><br>
      <br>
      <div style="margin-left: 40px;">def compute(split: Partition,
context: TaskContext): Iterator[T] </div>
      <br>
      <span style="font-weight: bold;">Example</span><br>
      <br>
      <div style="margin-left: 40px;">
      <table style="text-align: left; width: 586px; height: 65px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top; background-color: rgb(242, 242, 242);">val
c = sc.parallelize(List("Gnu", "Cat", "Rat", "Dog"), 2)<br>
c.context<br>
res8: org.apache.spark.SparkContext =
org.apache.spark.SparkContext@58c1c2f1</td>
          </tr>
        </tbody>
      </table>
      </div>
      <br>
      <br>
      <hr style="width: 100%; height: 2px;"><br>
      <a name="count"></a><br>
      <p class="p30 ft4"><big><big><span style="font-weight: bold;">count</span></big></big><br>
      </p>
      <div style="text-align: left;">Returns the number of items stored
within a RDD.<br>
      </div>
      <div style="margin-left: 40px;"><span style="font-weight: bold;"><br>
      </span></div>
      <span style="font-weight: bold;">Listing Variants</span><br>
      <br>
      <div style="margin-left: 40px;">def count(): Long </div>
      <br>
      <span style="font-weight: bold;">Example</span><br>
      <br>
      <div style="margin-left: 40px;">
      <table style="text-align: left; width: 586px; height: 65px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top; background-color: rgb(242, 242, 242);">val
c = sc.parallelize(List("Gnu", "Cat", "Rat", "Dog"), 2)<br>
c.count<br>
res2: Long = 4</td>
          </tr>
        </tbody>
      </table>
      </div>
      <br>
      <br>
      <hr style="width: 100%; height: 2px;"><br>
      <a name="countApprox"></a><br>
      <p class="p30 ft4"><big><big><span style="font-weight: bold;">countApprox</span></big></big><br>
      </p>
Marked as experimental feature! Experimental features are currently not
covered by this document!
      <div style="margin-left: 40px;"><span style="font-weight: bold;"><br>
      </span></div>
      <span style="font-weight: bold;">Listing Variants</span><br>
      <div style="margin-left: 40px;">def (timeout: Long, confidence:
Double = 0.95): PartialResult[BoundedDouble]<br>
      </div>
      <br>
      
      <hr style="width: 100%; height: 2px;"><br>
      <a name="countApproxDistinct"></a><br>

      <br>

      <big><big><span style="font-weight: bold;">countApproxDistinct</span></big></big><br>

      <br>

Computes the approximate number of distinct values. For large RDDs
which are spread across many nodes, this function may execute faster
than other counting methods. The parameter <span style="font-style: italic;">relativeSD</span> controls the accuracy of
the computation.<br>

      <br>

      <span style="font-weight: bold;">Listing Variants</span><br>

      <br>

      
      <div style="margin-left: 40px;">def
countApproxDistinct(relativeSD: Double = 0.05): Long<br>
      </div>

      <br>

      <span style="font-weight: bold;">Example</span><br>

      <br>

      
      <div style="margin-left: 40px;">
      <table style="text-align: left; width: 586px; height: 65px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top; background-color: rgb(242, 242, 242);">val
a = sc.parallelize(1 to 10000, 20)<br>
val b = a++a++a++a++a<br>
b.countApproxDistinct(0.1)<br>
res14: Long = 8224<br>
            <br>
b.countApproxDistinct(0.05)<br>
res15: Long = 9750<br>
            <br>
b.countApproxDistinct(0.01)<br>
res16: Long = 9947<br>
            <br>
b.countApproxDistinct(0.001)<br>
res0: Long = 10000<br>
            </td>
          </tr>
        </tbody>
      </table>
      </div>

      <br>

      <br>
      <br>

      
      <hr style="width: 100%; height: 2px;"><br>

      <a name="countApproxDistinceByKey"></a><br>

      <br>

      <big><big><span style="font-weight: bold;">countApproxDistinctByKey
      <small>[Pair]</small></span></big></big><br>

&nbsp; <br>

Similar to <span style="font-style: italic;">countApproxDistinct</span>,
but computes the approximate number of distinct values for each
distinct key. Hence, the RDD must consist of two-component tuples. For
large RDDs which are spread across many nodes, this function may
execute faster than other counting methods. The parameter <span style="font-style: italic;">relativeSD</span> controls the accuracy of
the computation.<br>

      <br>

      <span style="font-weight: bold;">Listing Variants</span><br>

      <br>

      
      <div style="margin-left: 40px;">def
countApproxDistinctByKey(relativeSD: Double = 0.05): RDD[(K, Long)]<br>
def countApproxDistinctByKey(relativeSD: Double, numPartitions: Int):
RDD[(K, Long)]<br>
def countApproxDistinctByKey(relativeSD: Double, partitioner:
Partitioner): RDD[(K, Long)]<br>
      </div>

      <br>

      <span style="font-weight: bold;">Example</span><br>

      <br>

      
      <div style="margin-left: 40px;">
      <table style="text-align: left; width: 586px; height: 65px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top; background-color: rgb(242, 242, 242);">val
a = sc.parallelize(List("Gnu", "Cat", "Rat", "Dog"), 2)<br>
val b = sc.parallelize(a.takeSample(true, 10000, 0), 20)<br>
val c = sc.parallelize(1 to b.count().toInt, 20)<br>
val d = b.zip(c)<br>
d.countApproxDistinctByKey(0.1).collect<br>
res15: Array[(String, Long)] = Array((Rat,2567), (Cat,3357),
(Dog,2414), (Gnu,2494))<br>
            <br>
d.countApproxDistinctByKey(0.01).collect<br>
res16: Array[(String, Long)] = Array((Rat,2555), (Cat,2455),
(Dog,2425), (Gnu,2513))<br>
            <br>
d.countApproxDistinctByKey(0.001).collect<br>
res0: Array[(String, Long)] = Array((Rat,2562), (Cat,2464), (Dog,2451),
(Gnu,2521))</td>
          </tr>
        </tbody>
      </table>
      </div>

      <br>
      <br>

      <hr style="width: 100%; height: 2px;"><br>
      <a name="countByKey"></a><br>
      <p class="p30 ft4"><big><big><span style="font-weight: bold;">countByKey
      <small>[Pair]</small></span></big></big><br>
      </p>
Very similar to count, but counts the values of a RDD consisting of
two-component tuples for each distinct key separately.
      <div style="margin-left: 40px;"><span style="font-weight: bold;"><br>
      </span></div>
      <span style="font-weight: bold;">Listing Variants</span><br>
      <br>
      <div style="margin-left: 40px;">def countByKey(): Map[K, Long]<br>
      </div>
      <br>
      <span style="font-weight: bold;">Example</span><br>
      <br>
      <div style="margin-left: 40px;">
      <table style="text-align: left; width: 586px; height: 65px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top; background-color: rgb(242, 242, 242);">val
c = sc.parallelize(List((3, "Gnu"), (3, "Yak"), (5, "Mouse"), (3,
"Dog")), 2)<br>
c.countByKey<br>
res3: scala.collection.Map[Int,Long] = Map(3 -&gt; 3, 5 -&gt; 1)</td>
          </tr>
        </tbody>
      </table>
      </div>
      <br>
      <br>
      <hr style="width: 100%; height: 2px;"><br>
      <br>
      <a name="countByKeyApprox"></a><br>
      <br>
      <p class="p30 ft4"><big><big><span style="font-weight: bold;">countByKeyApprox
      <small>[Pair]</small></span></big></big><br>
      </p>
Marked as experimental feature! Experimental features are currently not
covered by this document!
      <div style="margin-left: 40px;"><span style="font-weight: bold;"><br>
      </span></div>
      <span style="font-weight: bold;">Listing Variants</span><br>
      <br>
      <div style="margin-left: 40px;">def countByKeyApprox(timeout:
Long, confidence: Double = 0.95): PartialResult[Map[K, BoundedDouble]]<br>
      </div>
      <br>
      <br>
      <hr style="width: 100%; height: 2px;"><a name="countByValue"></a><br>
      <br>
      <br>
      <big><big><span style="font-weight: bold;">countByValue</span></big></big><br>
      <br>
Returns a map that contains all unique values of the RDD and their
respective occurrence counts.<span style="font-style: italic;">
(Warning: This operation will finally aggregate the information in a
single reducer.)</span><br>
      <br>
      <span style="font-weight: bold;">Listing Variants</span><br>
      <br>
      <div style="margin-left: 40px;">def countByValue(): Map[T, Long]<br>
      </div>
      <br>
      <span style="font-weight: bold;">Example</span><br>
      <br>
      <div style="margin-left: 40px;">
      <table style="text-align: left; width: 586px; height: 65px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top; background-color: rgb(242, 242, 242);">val
b = sc.parallelize(List(1,2,3,4,5,6,7,8,2,4,2,1,1,1,1,1))<br>
b.countByValue<br>
res27: scala.collection.Map[Int,Long] = Map(5 -&gt; 1, 8 -&gt; 1, 3
-&gt; 1, 6 -&gt; 1, 1 -&gt; 6, 2 -&gt; 3, 4 -&gt; 2, 7 -&gt; 1)</td>
          </tr>
        </tbody>
      </table>
      </div>
      <br>
      <br>
      <br>
      <hr style="width: 100%; height: 2px;"><br>
      <a name="countByValueApprox"></a><br>
      <p class="p30 ft4"><big><big><span style="font-weight: bold;">countByValueApprox</span></big></big><br>
      </p>
Marked as experimental feature! Experimental features are currently not
covered by this document!
      <div style="margin-left: 40px;"><span style="font-weight: bold;"><br>
      </span></div>
      <span style="font-weight: bold;">Listing Variants</span><br>
      <br>
      <div style="margin-left: 40px;">def countByValueApprox(timeout:
Long, confidence: Double = 0.95): PartialResult[Map[T, BoundedDouble]]<br>
      </div>
      <br>
      <br>
      <hr style="width: 100%; height: 2px;"><br>
      <a name="dependencies"></a><br>
      <br>
      <big><big><span style="font-weight: bold;">dependencies</span></big></big><br>
&nbsp; <br>
Returns the RDD on which this RDD depends.<br>
      <br>
      <span style="font-weight: bold;">Listing Variants</span><br>
      <br>
      <div style="margin-left: 40px;">final def dependencies:
Seq[Dependency[_]]<br>
      </div>
      <br>
      <span style="font-weight: bold;">Example</span><br>
      <br>
      <div style="margin-left: 40px;">
      <table style="text-align: left; width: 586px; height: 65px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top; background-color: rgb(242, 242, 242);">val
b = sc.parallelize(List(1,2,3,4,5,6,7,8,2,4,2,1,1,1,1,1))<br>
b: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[32] at
parallelize at &lt;console&gt;:12<br>
b.dependencies.length<br>
Int = 0<br>
            <br>
b.map(a =&gt; a).dependencies.length<br>
res40: Int = 1<br>
            <br>
b.cartesian(a).dependencies.length<br>
res41: Int = 2<br>
            <br>
b.cartesian(a).dependencies<br>
res42: Seq[org.apache.spark.Dependency[_]] =
List(org.apache.spark.rdd.CartesianRDD$$anon$1@576ddaaa,
org.apache.spark.rdd.CartesianRDD$$anon$2@6d2efbbd)</td>
          </tr>
        </tbody>
      </table>
      </div>
      <br>
      <br>
      <br>
      <hr style="width: 100%; height: 2px;"><br>
      <a name="distinct"></a><br>
      <br>
      <big><big><span style="font-weight: bold;">distinct</span></big></big><br>
&nbsp; <br>
Returns a new RDD that contains each unique value only once.<br>
      <br>
      <span style="font-weight: bold;">Listing Variants</span><br>
      <br>
      <div style="margin-left: 40px;">def distinct(): RDD[T]<br>
def distinct(numPartitions: Int): RDD[T]<br>
      </div>
      <br>
      <span style="font-weight: bold;">Example</span><br>
      <br>
      <div style="margin-left: 40px;">
      <table style="text-align: left; width: 586px; height: 65px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top; background-color: rgb(242, 242, 242);">val
c = sc.parallelize(List("Gnu", "Cat", "Rat", "Dog", "Gnu", "Rat"), 2)<br>
c.distinct.collect<br>
res6: Array[String] = Array(Dog, Gnu, Cat, Rat)<br>
            <br>
val a = sc.parallelize(List(1,2,3,4,5,6,7,8,9,10))<br>
a.distinct(2).partitions.length<br>
res16: Int = 2<br>
            <br>
a.distinct(3).partitions.length<br>
res17: Int = 3</td>
          </tr>
        </tbody>
      </table>
      </div>
      <br>
      <br>
      <hr style="width: 100%; height: 2px;"><br>
      <br>
      <a name="first"></a><br>
      <br>
      <big><big><span style="font-weight: bold;">first</span></big></big><br>
&nbsp; <br>
Looks for the very first data item of the RDD and returns it.<br>
      <br>
      <span style="font-weight: bold;">Listing Variants</span><br>
      <br>
      <div style="margin-left: 40px;">def first(): T<br>
      </div>
      <br>
      <span style="font-weight: bold;">Example</span><br>
      <br>
      <div style="margin-left: 40px;">
      <table style="text-align: left; width: 586px; height: 65px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top; background-color: rgb(242, 242, 242);">val
c = sc.parallelize(List("Gnu", "Cat", "Rat", "Dog"), 2)<br>
c.first<br>
res1: String = Gnu</td>
          </tr>
        </tbody>
      </table>
      </div>
      <br>
      <br>
      <br>
      <hr style="width: 100%; height: 2px;"><br>
      <a name="filter"></a><br>
      <br>
      <big><big><span style="font-weight: bold;">filter</span></big></big><br>
&nbsp; <br>
Evaluates a boolean function for each data item of the RDD and puts the
items for which the function returned <span style="font-style: italic;">true</span>
into the resulting RDD.<br>
      <br>
      <span style="font-weight: bold;">Listing Variants</span><br>
      <br>
      <div style="margin-left: 40px;">def filter(f: T =&gt; Boolean):
RDD[T]<br>
      </div>
      <br>
      <span style="font-weight: bold;">Example</span><br>
      <br>
      <div style="margin-left: 40px;">
      <table style="text-align: left; width: 586px; height: 65px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top; background-color: rgb(242, 242, 242);">val
a = sc.parallelize(1 to 10, 3)<br>
val b = a.filter(_ % 2 == 0)<br>
b.collect<br>
res3: Array[Int] = Array(2, 4, 6, 8, 10)</td>
          </tr>
        </tbody>
      </table>
      </div>
      <br>
When you provide a filter function, it must be able to handle all data
items contained in the RDD. Scala provides so-called partial functions
to deal with mixed data-types. (Tip: Partial functions are very useful
if you have some data which may be bad and you do not want to handle
but for the good data (matching data) you want to apply some kind of
map function. The following article is good. It teaches you about
partial functions in a very nice way and explains why case has to be
used for partial functions:&nbsp;&nbsp;<a href="http://blog.bruchez.name/2011/10/scala-partial-functions-without-phd.html">article</a>)<br>
      <br>
      <span style="font-weight: bold;">Examples for mixed data without
partial functions</span><br>
      <br>
      <div style="margin-left: 40px;">
      <table style="text-align: left; width: 586px; height: 65px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top; background-color: rgb(242, 242, 242);">val
b = sc.parallelize(1 to 8)<br>
b.filter(_ &lt; 4).collect<br>
res15: Array[Int] = Array(1, 2, 3)<br>
            <br>
val a = sc.parallelize(List("cat", "horse", 4.0, 3.5, 2, "dog"))<br>
a.filter(_ &lt; 4).collect<br>
&lt;console&gt;:15: error: value &lt; is not a member of Any</td>
          </tr>
        </tbody>
      </table>
      </div>
      <br>
This fails because some components of <span style="font-style: italic;">a
      </span>are not implicitly comparable against integers. Collect
uses the <span style="font-style: italic;">isDefinedAt </span>property
of a function-object to determine whether the test-function is
compatible with each data item. Only data items that pass this test <span style="font-style: italic;">(=filter) </span>are then mapped using
the function-object.<br>
      <br>
      <span style="font-weight: bold;">Examples for mixed data with
partial functions</span><br>
      <br>
      <div style="margin-left: 40px;">
      <table style="text-align: left; width: 586px; height: 65px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top; background-color: rgb(242, 242, 242);">val
a = sc.parallelize(List("cat", "horse", 4.0, 3.5, 2, "dog"))<br>
a.collect({case a: Int&nbsp;&nbsp;&nbsp; =&gt; "is integer" |<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; case b:
String =&gt; "is string" }).collect<br>
res17: Array[String] = Array(is string, is string, is integer, is
string)<br>
            <br>
val myfunc: PartialFunction[Any, Any] = {<br>
&nbsp; case a: Int&nbsp;&nbsp;&nbsp; =&gt; "is integer" |<br>
&nbsp; case b: String =&gt; "is string" }<br>
myfunc.isDefinedAt("")<br>
res21: Boolean = true<br>
            <br>
myfunc.isDefinedAt(1)<br>
res22: Boolean = true<br>
            <br>
myfunc.isDefinedAt(1.5)<br>
res23: Boolean = false</td>
          </tr>
        </tbody>
      </table>
      </div>
      <br>
      <br>
Be careful! The above code works because it only checks the type
itself! If you use operations on this type, you have to explicitly
declare what type you want instead of any. Otherwise the compiler does
(apparently) not know what bytecode it should produce:<br>
      <br>
      <div style="margin-left: 40px;">
      <table style="text-align: left; width: 586px; height: 65px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top; background-color: rgb(242, 242, 242);">val
myfunc2: PartialFunction[Any, Any] = {case x if (x &lt; 4) =&gt; "x"}<br>
&lt;console&gt;:10: error: value &lt; is not a member of Any<br>
            <br>
val myfunc2: PartialFunction[Int, Any] = {case x if (x &lt; 4) =&gt;
"x"}<br>
myfunc2: PartialFunction[Int,Any] = &lt;function1&gt;</td>
          </tr>
        </tbody>
      </table>
      </div>
      <br>
      <br>
      <hr style="width: 100%; height: 2px;"><br>
      <a name="filterByRange"></a><br>
      <br>
      <big><big><span style="font-weight: bold;">filterByRange </span></big></big>[Ordered]<br>

&nbsp; <br>
Returns an RDD containing only the items in the key range specified.
From our testing, it appears this only works if your data is in key
value pairs and it has already been sorted by key.<br>
      <br>

      <span style="font-weight: bold;">Listing Variants</span><br>

      <br>
      <div style="margin-left: 40px;">def filterByRange(lower: K, upper: K): RDD[P]<br>
      </div>

      <span style="font-weight: bold;"><br>
Example</span><br>

      <br>
      <br>
      <table style="text-align: left; width: 643px; margin-left: 40px; height: 33px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top;">val randRDD = sc.parallelize(List( (2,"cat"), (6, "mouse"),(7, "cup"), (3, "book"), (4, "tv"), (1, "screen"), (5, "heater")), 3)<br>
val sortedRDD = randRDD.sortByKey()<br>
            <br>
sortedRDD.filterByRange(1, 3).collect<br>
res66: Array[(Int, String)] = Array((1,screen), (2,cat), (3,book))<br>
            </td>
          </tr>
        </tbody>
      </table>
      <br>
      <br>
<hr style="width: 100%; height: 2px;"><br>
      <a name="filterWith"></a><br>
      <br>
      <big><big><span style="font-weight: bold;">filterWith</span></big></big>&nbsp; <big><span style="font-weight: bold;">(deprecated)</span></big><br>
&nbsp; <br>
This is an extended version of <span style="font-style: italic;">filter</span>.
It takes two function arguments. The first argument must conform to <span style="font-style: italic;">Int -&gt; T</span> and is executed once
per partition. It will transform the partition index to type <span style="font-style: italic;">T</span>. The second function looks like<span style="font-style: italic;"> (U, T) -&gt; Boolean</span>. <span style="font-style: italic;">T</span> is the transformed partition
index and <span style="font-style: italic;">U</span> are the data
items from the RDD. Finally the function has to return either true or
false <span style="font-style: italic;">(i.e. Apply the filter)</span>.<br>
      <br>
      <span style="font-weight: bold;">Listing Variants</span><br>
      <br>
      <div style="margin-left: 40px;">def filterWith[A:
ClassTag](constructA: Int =&gt; A)(p: (T, A) =&gt; Boolean): RDD[T]<br>
      </div>
      <br>
      <span style="font-weight: bold;">Example</span><br>
      <br>
      <div style="margin-left: 40px;">
      <table style="text-align: left; width: 586px; height: 65px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top; background-color: rgb(242, 242, 242);">val
a = sc.parallelize(1 to 9, 3)<br>
val b = a.filterWith(i =&gt; i)((x,i) =&gt; x % 2 == 0 || i % 2 == 0)<br>
b.collect<br>
res37: Array[Int] = Array(1, 2, 3, 4, 6, 7, 8, 9)<br>
            <br>
val a = sc.parallelize(List(1,2,3,4,5,6,7,8,9,10), 5)<br>
a.filterWith(x=&gt; x)((a, b) =&gt;&nbsp; b == 0).collect<br>
res30: Array[Int] = Array(1, 2)<br>
            <br>
a.filterWith(x=&gt; x)((a, b) =&gt;&nbsp; a % (b+1) == 0).collect<br>
res33: Array[Int] = Array(1, 2, 4, 6, 8, 10)<br>
            <br>
a.filterWith(x=&gt; x.toString)((a, b) =&gt;&nbsp; b == "2").collect<br>
res34: Array[Int] = Array(5, 6)</td>
          </tr>
        </tbody>
      </table>
      </div>
      <br>
      <br>
      <br>
      <hr style="width: 100%; height: 2px;"><br>
      <a name="flatMap"></a><br>
      <br>
      <big><big><span style="font-weight: bold;">flatMap</span></big></big><br>
&nbsp; <br>
Similar to <span style="font-style: italic;">map</span>, but allows
emitting more than one item in the map function.<br>
      <br>
      <span style="font-weight: bold;">Listing Variants</span><br>
      <br>
      <div style="margin-left: 40px;">def flatMap[U: ClassTag](f: T
=&gt; TraversableOnce[U]): RDD[U]<br>
      </div>
      <br>
      <span style="font-weight: bold;">Example</span><br>
      <br>
      <div style="margin-left: 40px;">
      <table style="text-align: left; width: 586px; height: 65px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top; background-color: rgb(242, 242, 242);">val
a = sc.parallelize(1 to 10, 5)<br>
a.flatMap(1 to _).collect<br>
res47: Array[Int] = Array(1, 1, 2, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 4, 5,
1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3,
4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10)<br>
            <br>
sc.parallelize(List(1, 2, 3), 2).flatMap(x =&gt; List(x, x, x)).collect<br>
res85: Array[Int] = Array(1, 1, 1, 2, 2, 2, 3, 3, 3)<br>
            <br>
// The program below generates a random number of copies (up to 10) of
the items in the list.<br>
val x&nbsp; = sc.parallelize(1 to 10, 3)<br>
x.flatMap(List.fill(scala.util.Random.nextInt(10))(_)).collect<br>
            <br>
res1: Array[Int] = Array(1, 2, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5,
5, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9,
9, 10, 10, 10, 10, 10, 10, 10, 10)</td>
          </tr>
        </tbody>
      </table>
      </div>
      <br>
      <br>
      <br>
      <hr style="width: 100%; height: 2px;"><br>
      <a name="flatMapValues"></a><br>
      <br>
      <big><big><span style="font-weight: bold;">flatMapValues</span></big></big><br>
&nbsp; <br>
Very similar to <span style="font-style: italic;">mapValues</span>,
but collapses the inherent structure of the values during mapping.<br>
      <br>
      <span style="font-weight: bold;">Listing Variants</span><br>
      <br>
      <div style="margin-left: 40px;">def flatMapValues[U](f: V =&gt;
TraversableOnce[U]): RDD[(K, U)]<br>
      </div>
      <br>
      <span style="font-weight: bold;">Example</span><br>
      <br>
      <div style="margin-left: 40px;">
      <table style="text-align: left; width: 586px; height: 65px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top; background-color: rgb(242, 242, 242);">val
a = sc.parallelize(List("dog", "tiger", "lion", "cat", "panther",
"eagle"), 2)<br>
val b = a.map(x =&gt; (x.length, x))<br>
b.flatMapValues("x" + _ + "x").collect<br>
res6: Array[(Int, Char)] = Array((3,x), (3,d), (3,o), (3,g), (3,x),
(5,x), (5,t), (5,i), (5,g), (5,e), (5,r), (5,x), (4,x), (4,l), (4,i),
(4,o), (4,n), (4,x), (3,x), (3,c), (3,a), (3,t), (3,x), (7,x), (7,p),
(7,a), (7,n), (7,t), (7,h), (7,e), (7,r), (7,x), (5,x), (5,e), (5,a),
(5,g), (5,l), (5,e), (5,x))</td>
          </tr>
        </tbody>
      </table>
      </div>
      <br>
      <br>
      <hr style="width: 100%; height: 2px;"><br>
      <a name="flatMapWith"></a><br>
      <br>
      <big><big><span style="font-weight: bold;">flatMapWith</span></big></big> <big><span style="font-weight: bold;">(deprecated)</span></big><br>
&nbsp; <br>
Similar to <span style="font-style: italic;">flatMap</span>, but
allows accessing the partition index or a derivative of the partition
index from within the flatMap-function.<br>
      <br>
      <span style="font-weight: bold;">Listing Variants</span><br>
      <br>
      <div style="margin-left: 40px;">def flatMapWith[A: ClassTag, U:
ClassTag](constructA: Int =&gt; A, preservesPartitioning: Boolean =
false)(f: (T, A) =&gt; Seq[U]): RDD[U]<br>
      </div>
      <br>
      <span style="font-weight: bold;">Example</span><br>
      <br>
      <div style="margin-left: 40px;">
      <table style="text-align: left; width: 586px; height: 65px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top; background-color: rgb(242, 242, 242);">val
a = sc.parallelize(List(1,2,3,4,5,6,7,8,9), 3)<br>
a.flatMapWith(x =&gt; x, true)((x, y) =&gt; List(y, x)).collect<br>
res58: Array[Int] = Array(0, 1, 0, 2, 0, 3, 1, 4, 1, 5, 1, 6, 2, 7, 2,
8, 2, 9)</td>
          </tr>
        </tbody>
      </table>
      </div>
      <br>
      <br>
      <hr style="width: 100%; height: 2px;"><br>
      <a name="fold"></a><br>
      <br>
      <big><big><span style="font-weight: bold;">fold</span></big></big><br>
&nbsp; <br>
Aggregates the values of each partition. The aggregation variable
within each partition is initialized with <span style="font-style: italic;">zeroValue</span>.<br>
      <br>
      <span style="font-weight: bold;">Listing Variants</span><br>
      <br>
      <div style="margin-left: 40px;">def fold(zeroValue: T)(op: (T, T)
=&gt; T): T<br>
      </div>
      <br>
      <span style="font-weight: bold;">Example</span><br>
      <br>
      <div style="margin-left: 40px;">
      <table style="text-align: left; width: 586px; height: 65px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top; background-color: rgb(242, 242, 242);">val
a = sc.parallelize(List(1,2,3), 3)<br>
a.fold(0)(_ + _)<br>
res59: Int = 6</td>
          </tr>
        </tbody>
      </table>
      </div>
      <br>
      <br>
      <hr style="width: 100%; height: 2px;"><br>
      <a name="foldByKey"></a><br>
      <br>
      <big><big><span style="font-weight: bold;">foldByKey <small>[Pair]</small></span></big></big><br>
&nbsp; <br>
Very similar to <span style="font-style: italic;">fold</span>, but
performs the folding separately for each key of the RDD. This function
is only available if the RDD consists of two-component tuples.<br>
      <br>
      <span style="font-weight: bold;">Listing Variants</span><br>
      <br>
      <div style="margin-left: 40px;">def foldByKey(zeroValue: V)(func:
(V, V) =&gt; V): RDD[(K, V)]<br>
def foldByKey(zeroValue: V, numPartitions: Int)(func: (V, V) =&gt; V):
RDD[(K, V)]<br>
def foldByKey(zeroValue: V, partitioner: Partitioner)(func: (V, V)
=&gt; V): RDD[(K, V)]<br>
      </div>
      <br>
      <span style="font-weight: bold;">Example</span><br>
      <br>
      <div style="margin-left: 40px;">
      <table style="text-align: left; width: 586px; height: 65px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top; background-color: rgb(242, 242, 242);">val
a = sc.parallelize(List("dog", "cat", "owl", "gnu", "ant"), 2)<br>
val b = a.map(x =&gt; (x.length, x))<br>
b.foldByKey("")(_ + _).collect<br>
res84: Array[(Int, String)] = Array((3,dogcatowlgnuant)<br>
            <br>
val a = sc.parallelize(List("dog", "tiger", "lion", "cat", "panther",
"eagle"), 2)<br>
val b = a.map(x =&gt; (x.length, x))<br>
b.foldByKey("")(_ + _).collect<br>
res85: Array[(Int, String)] = Array((4,lion), (3,dogcat), (7,panther),
(5,tigereagle))</td>
          </tr>
        </tbody>
      </table>
      </div>
      <br>
      <br>
      <br>
      <hr style="width: 100%; height: 2px;"><br>
      <a name="foreach"></a><br>
      <br>
      <big><big><span style="font-weight: bold;">foreach</span></big></big><br>
&nbsp; <br>
Executes an parameterless function for each data item.<br>
      <br>
      <span style="font-weight: bold;">Listing Variants</span><br>
      <br>
      <div style="margin-left: 40px;">def foreach(f: T =&gt; Unit)<br>
      </div>
      <br>
      <span style="font-weight: bold;">Example</span><br>
      <br>
      <div style="margin-left: 40px;">
      <table style="text-align: left; width: 586px; height: 65px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top; background-color: rgb(242, 242, 242);">val
c = sc.parallelize(List("cat", "dog", "tiger", "lion", "gnu",
"crocodile", "ant", "whale", "dolphin", "spider"), 3)<br>
c.foreach(x =&gt; println(x + "s are yummy"))<br>
lions are yummy<br>
gnus are yummy<br>
crocodiles are yummy<br>
ants are yummy<br>
whales are yummy<br>
dolphins are yummy<br>
spiders are yummy</td>
          </tr>
        </tbody>
      </table>
      <br>
      </div>
      <br>
      <br>
      <hr style="width: 100%; height: 2px;"><br>
      <a name="foreachPartition"></a><br>
      <br>
      <big><big><span style="font-weight: bold;">foreachPartition</span></big></big><br>
&nbsp; <br>
Executes an parameterless function for each partition. Access to the
data items contained in the partition is provided via the iterator
argument.<br>
      <br>
      <span style="font-weight: bold;">Listing Variants</span><br>
      <br>
      <div style="margin-left: 40px;">def foreachPartition(f:
Iterator[T] =&gt; Unit)<br>
      </div>
      <br>
      <span style="font-weight: bold;">Example</span><br>
      <br>
      <div style="margin-left: 40px;">
      <table style="text-align: left; width: 586px; height: 65px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top; background-color: rgb(242, 242, 242);">val
b = sc.parallelize(List(1, 2, 3, 4, 5, 6, 7, 8, 9), 3)<br>
b.foreachPartition(x =&gt; println(x.reduce(_ + _)))<br>
6<br>
15<br>
24</td>
          </tr>
        </tbody>
      </table>
      </div>
      <br>
      <br>
      <br>
      <hr style="width: 100%; height: 2px;"><br>
      <a name="foreachWith"></a><br>
      <br>
      <big><big><span style="font-weight: bold;">foreachWith</span></big></big> <big><span style="font-weight: bold;">(Deprecated)</span></big><br>
&nbsp; <br>
Executes an parameterless function for each partition. Access to the
data items contained in the partition is provided via the iterator
argument.<br>
      <br>
      <span style="font-weight: bold;">Listing Variants</span><br>
      <br>
      <div style="margin-left: 40px;">def foreachWith[A:
ClassTag](constructA: Int =&gt; A)(f: (T, A) =&gt; Unit)<br>
      </div>
      <br>
      <span style="font-weight: bold;">Example</span><br>
      <br>
      <div style="margin-left: 40px;">
      <table style="text-align: left; width: 586px; height: 65px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top; background-color: rgb(242, 242, 242);">val
a = sc.parallelize(1 to 9, 3)<br>
a.foreachWith(i =&gt; i)((x,i) =&gt; if (x % 2 == 1 &amp;&amp; i % 2 ==
0) println(x) )<br>
1<br>
3<br>
7<br>
9</td>
          </tr>
        </tbody>
      </table>
      </div>
      <br>
      <br>
      
      <hr style="width: 100%; height: 2px;"><br>
      <a name="fullOuterJoin"></a><br>
      <br>
      <big><big><span style="font-weight: bold;">fullOuterJoin</span></big></big><big><span style="font-weight: bold;"></span></big> [Pair]<br>

&nbsp; <br>
Performs the full outer join between two paired RDDs.<br>

      <br>

      <span style="font-weight: bold;">Listing Variants</span><br>

      <br>

      
      <div style="margin-left: 40px;">def fullOuterJoin[W](other: RDD[(K, W)], numPartitions: Int): RDD[(K, (Option[V], Option[W]))]<br>
def fullOuterJoin[W](other: RDD[(K, W)]): RDD[(K, (Option[V], Option[W]))]<br>
def fullOuterJoin[W](other: RDD[(K, W)], partitioner: Partitioner): RDD[(K, (Option[V], Option[W]))]<br>
      </div>

      <br>

      <span style="font-weight: bold;">Example</span><br>
      <br>
      <table style="text-align: left; width: 637px; margin-left: 40px; height: 26px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top;">val pairRDD1 = sc.parallelize(List( ("cat",2), ("cat", 5), ("book", 4),("cat", 12)))<br>
val pairRDD2 = sc.parallelize(List( ("cat",2), ("cup", 5), ("mouse", 4),("cat", 12)))<br>
pairRDD1.fullOuterJoin(pairRDD2).collect<br>
            <br>
res5: Array[(String, (Option[Int], Option[Int]))] =
Array((book,(Some(4),None)), (mouse,(None,Some(4))),
(cup,(None,Some(5))), (cat,(Some(2),Some(2))),
(cat,(Some(2),Some(12))), (cat,(Some(5),Some(2))),
(cat,(Some(5),Some(12))), (cat,(Some(12),Some(2))),
(cat,(Some(12),Some(12))))<br>
            </td>
          </tr>
        </tbody>
      </table>
      <br>
      <br>
<br>
      <hr style="width: 100%; height: 2px;"><br>
      <a name="generator"></a><br>
      <br>
      <big><big><span style="font-weight: bold;">generator, setGenerator</span></big></big><br>
&nbsp; <br>
Allows setting a string that is attached to the end of the RDD's name
when printing the dependency graph.<br>
      <br>
      <span style="font-weight: bold;">Listing Variants</span><br>
      <br>
      <div style="margin-left: 40px;">@transient var generator<br>
def setGenerator(_generator: String)<br>
      </div>
      <br>
      <br>
      <hr style="width: 100%; height: 2px;"><br>
      <a name="getCheckpointFile"></a><br>
      <br>
      <big><big><span style="font-weight: bold;">getCheckpointFile</span></big></big><br>
&nbsp; <br>
Returns the path to the checkpoint file or null if RDD has not yet been
checkpointed.<br>
      <br>
      <span style="font-weight: bold;">Listing Variants</span><br>
      <br>
      <div style="margin-left: 40px;">def getCheckpointFile:
Option[String]</div>
      <br>
      <span style="font-weight: bold;">Example</span><br>
      <br>
      <div style="margin-left: 40px;">
      <table style="text-align: left; width: 586px; height: 65px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top; background-color: rgb(242, 242, 242);">sc.setCheckpointDir("/home/cloudera/Documents")<br>
val a = sc.parallelize(1 to 500, 5)<br>
val b = a++a++a++a++a<br>
b.getCheckpointFile<br>
res49: Option[String] = None<br>
            <br>
b.checkpoint<br>
b.getCheckpointFile<br>
res54: Option[String] = None<br>
            <br>
b.collect<br>
b.getCheckpointFile<br>
res57: Option[String] =
Some(file:/home/cloudera/Documents/cb978ffb-a346-4820-b3ba-d56580787b20/rdd-40)</td>
          </tr>
        </tbody>
      </table>
      </div>
      <br>
      <br>
      <hr style="width: 100%; height: 2px;"><br>
      <a name="preferredLocations"></a><br>
      <br>
      <big><big><span style="font-weight: bold;">preferredLocations</span></big></big><br>
&nbsp; <br>
Returns the hosts which are preferred by this RDD. The actual
preference of a specific host depends on various assumptions.<br>
      <br>
      <span style="font-weight: bold;">Listing Variants</span><br>
      <br>
      <div style="margin-left: 40px;">final def
preferredLocations(split: Partition): Seq[String]</div>
      <br>
      <br>
      <br>
      <hr style="width: 100%; height: 2px;"><br>
      <a name="getStorageLevel"></a><br>
      <br>
      <big><big><span style="font-weight: bold;">getStorageLevel</span></big></big><br>
&nbsp; <br>
Retrieves the currently set storage level of the RDD. This can only be
used to assign a new storage level if the RDD does not have a storage
level set yet. The example below shows the error you will get, when you
try to reassign the storage level.<br>
      <br>
      <span style="font-weight: bold;">Listing Variants</span><br>
      <br>
      <div style="margin-left: 40px;">def getStorageLevel</div>
      <br>
      <span style="font-weight: bold;">Example</span><br>
      <br>
      <div style="margin-left: 40px;">
      <table style="text-align: left; width: 586px; height: 65px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top; background-color: rgb(242, 242, 242);">val
a = sc.parallelize(1 to 100000, 2)<br>
a.persist(org.apache.spark.storage.StorageLevel.DISK_ONLY)<br>
a.getStorageLevel.description<br>
String = Disk Serialized 1x Replicated<br>
            <br>
a.cache<br>
java.lang.UnsupportedOperationException: Cannot change storage level of
an RDD after it was already assigned a level</td>
          </tr>
        </tbody>
      </table>
      </div>
      <br>
      <br>
      <br>
      <hr style="width: 100%; height: 2px;"><br>
      <br>
      <a name="glom"></a><br>
      <br>
      <big><big><span style="font-weight: bold;">glom</span></big></big><br>
&nbsp; <br>
Assembles an array that contains all elements of the partition and
embeds it in an RDD. Each returned array contains the contents of one partition.<br>
      <br>
      <span style="font-weight: bold;">Listing Variants</span><br>
      <br>
      <div style="margin-left: 40px;">def glom(): RDD[Array[T]]</div>
      <br>
      <span style="font-weight: bold;">Example<br>
      <br>
      </span>
      <div style="margin-left: 40px;">
      <table style="text-align: left; width: 586px; height: 65px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top; background-color: rgb(242, 242, 242);">val
a = sc.parallelize(1 to 100, 3)<br>
a.glom.collect<br>
res8: Array[Array[Int]] = Array(Array(1, 2, 3, 4, 5, 6, 7, 8, 9, 10,
11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28,
29, 30, 31, 32, 33), Array(34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44,
45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62,
63, 64, 65, 66), Array(67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78,
79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96,
97, 98, 99, 100))</td>
          </tr>
        </tbody>
      </table>
      </div>
      <span style="font-weight: bold;"><br>
      <br>
      </span>
      <hr style="width: 100%; height: 2px;"><span style="font-weight: bold;"><br>
      <a name="groupBy"></a><br>
      <br>
      </span><big><big><span style="font-weight: bold;">groupBy</span></big></big><br>
&nbsp; <br>
      <br>
      <span style="font-weight: bold;">Listing Variants</span><br>
      <br>
      <div style="margin-left: 40px;">def groupBy[K: ClassTag](f: T
=&gt; K): RDD[(K, Iterable[T])]<br>
def groupBy[K: ClassTag](f: T =&gt; K, numPartitions: Int): RDD[(K,
Iterable[T])]<br>
def groupBy[K: ClassTag](f: T =&gt; K, p: Partitioner): RDD[(K,
Iterable[T])]</div>
      <br>
      <span style="font-weight: bold;">Example</span><br>
      <br>
      <div style="margin-left: 40px;">
      <table style="text-align: left; width: 586px; height: 65px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top; background-color: rgb(242, 242, 242);">val
a = sc.parallelize(1 to 9, 3)<br>
a.groupBy(x =&gt; { if (x % 2 == 0) "even" else "odd" }).collect<br>
res42: Array[(String, Seq[Int])] = Array((even,ArrayBuffer(2, 4, 6,
8)), (odd,ArrayBuffer(1, 3, 5, 7, 9)))<br>
            <br>
val a = sc.parallelize(1 to 9, 3)<br>
def myfunc(a: Int) : Int =<br>
{<br>
&nbsp; a % 2<br>
}<br>
a.groupBy(myfunc).collect<br>
res3: Array[(Int, Seq[Int])] = Array((0,ArrayBuffer(2, 4, 6, 8)),
(1,ArrayBuffer(1, 3, 5, 7, 9)))<br>
            <br>
val a = sc.parallelize(1 to 9, 3)<br>
def myfunc(a: Int) : Int =<br>
{<br>
&nbsp; a % 2<br>
}<br>
a.groupBy(x =&gt; myfunc(x), 3).collect<br>
a.groupBy(myfunc(_), 1).collect<br>
res7: Array[(Int, Seq[Int])] = Array((0,ArrayBuffer(2, 4, 6, 8)),
(1,ArrayBuffer(1, 3, 5, 7, 9)))<br>
            <br>
import org.apache.spark.Partitioner<br>
class MyPartitioner extends Partitioner {<br>
def numPartitions: Int = 2<br>
def getPartition(key: Any): Int =<br>
{<br>
&nbsp;&nbsp;&nbsp; key match<br>
&nbsp;&nbsp;&nbsp; {<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; case null&nbsp;&nbsp;&nbsp;&nbsp; =&gt; 0<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; case key: Int =&gt;
key&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; %
numPartitions<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; case
_&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; =&gt; key.hashCode %
numPartitions<br>
&nbsp;&nbsp;&nbsp; }<br>
&nbsp; }<br>
&nbsp; override def equals(other: Any): Boolean =<br>
&nbsp; {<br>
&nbsp;&nbsp;&nbsp; other match<br>
&nbsp;&nbsp;&nbsp; {<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; case h: MyPartitioner =&gt; true<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; case
_&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
=&gt; false<br>
&nbsp;&nbsp;&nbsp; }<br>
&nbsp; }<br>
}<br>
val a = sc.parallelize(1 to 9, 3)<br>
val p = new MyPartitioner()<br>
val b = a.groupBy((x:Int) =&gt; { x }, p)<br>
val c = b.mapWith(i =&gt; i)((a, b) =&gt; (b, a))<br>
c.collect<br>
res42: Array[(Int, (Int, Seq[Int]))] = Array((0,(4,ArrayBuffer(4))),
(0,(2,ArrayBuffer(2))), (0,(6,ArrayBuffer(6))), (0,(8,ArrayBuffer(8))),
(1,(9,ArrayBuffer(9))), (1,(3,ArrayBuffer(3))), (1,(1,ArrayBuffer(1))),
(1,(7,ArrayBuffer(7))), (1,(5,ArrayBuffer(5))))<br>
            </td>
          </tr>
        </tbody>
      </table>
      </div>
      <span style="font-weight: bold;"><br>
      <br>
      <br>
      </span>
      <hr style="width: 100%; height: 2px;"><span style="font-weight: bold;"><br>
      <a name="groupByKey"></a><br>
      <br>
      </span><big><big><span style="font-weight: bold;">groupByKey <small>[Pair]</small></span></big></big><br>
&nbsp; <br>
Very similar to <span style="font-style: italic;">groupBy</span>, but
instead of supplying a function, the key-component of each pair will
automatically be presented to the partitioner.<br>
      <br>
      <span style="font-weight: bold;">Listing Variants</span><br>
      <br>
      <div style="margin-left: 40px;">def groupByKey(): RDD[(K,
Iterable[V])]<br>
def groupByKey(numPartitions: Int): RDD[(K, Iterable[V])]<br>
def groupByKey(partitioner: Partitioner): RDD[(K, Iterable[V])]</div>
      <br>
      <span style="font-weight: bold;">Example</span><br>
      <br>
      <div style="margin-left: 40px;">
      <table style="text-align: left; width: 586px; height: 65px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top; background-color: rgb(242, 242, 242);">val
a = sc.parallelize(List("dog", "tiger", "lion", "cat", "spider",
"eagle"), 2)<br>
val b = a.keyBy(_.length)<br>
b.groupByKey.collect<br>
res11: Array[(Int, Seq[String])] = Array((4,ArrayBuffer(lion)),
(6,ArrayBuffer(spider)), (3,ArrayBuffer(dog, cat)),
(5,ArrayBuffer(tiger, eagle)))</td>
          </tr>
        </tbody>
      </table>
      </div>
      <br>
      <br>
      <hr style="width: 100%; height: 2px;"><br>
      <a name="histogram"></a><br>
      <br>
      <big><big><span style="font-weight: bold;">histogram <small>[Double]</small></span></big></big><br>
&nbsp; <br>
These functions take an RDD of doubles and create a histogram with
either even spacing (the number of buckets equals to <span style="font-style: italic;">bucketCount</span>)
or arbitrary spacing based on&nbsp; custom bucket boundaries supplied
by the user via an array of double values. The result type of both
variants is slightly different, the first function will return a tuple
consisting of two arrays. The first array contains the computed bucket
boundary values and the second array contains the corresponding count
of values <span style="font-style: italic;">(i.e. the histogram)</span>.
The second variant of the function will just return the histogram as an
array of integers.<br>
      <br>
      <span style="font-weight: bold;">Listing Variants</span><br>
      <br>
      <div style="margin-left: 40px;">def histogram(bucketCount: Int):
Pair[Array[Double], Array[Long]]<br>
def histogram(buckets: Array[Double], evenBuckets: Boolean = false):
Array[Long]</div>
      <br>
      <span style="font-weight: bold;">Example with even spacing</span><br>
      <br>
      <div style="margin-left: 40px;">
      <table style="text-align: left; width: 586px; height: 65px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top; background-color: rgb(242, 242, 242);">val
a = sc.parallelize(List(1.1, 1.2, 1.3, 2.0, 2.1, 7.4, 7.5, 7.6, 8.8,
9.0), 3)<br>
a.histogram(5)<br>
res11: (Array[Double], Array[Long]) = (Array(1.1, 2.68, 4.26, 5.84,
7.42, 9.0),Array(5, 0, 0, 1, 4))<br>
            <br>
val a = sc.parallelize(List(9.1, 1.0, 1.2, 2.1, 1.3, 5.0, 2.0, 2.1,
7.4, 7.5, 7.6, 8.8, 10.0, 8.9, 5.5), 3)<br>
a.histogram(6)<br>
res18: (Array[Double], Array[Long]) = (Array(1.0, 2.5, 4.0, 5.5, 7.0,
8.5, 10.0),Array(6, 0, 1, 1, 3, 4))</td>
          </tr>
        </tbody>
      </table>
      </div>
      <br>
      <br>
      <span style="font-weight: bold;">Example with custom spacing</span><br>
      <br>
      <div style="margin-left: 40px;">
      <table style="text-align: left; width: 586px; height: 65px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top; background-color: rgb(242, 242, 242);">val
a = sc.parallelize(List(1.1, 1.2, 1.3, 2.0, 2.1, 7.4, 7.5, 7.6, 8.8,
9.0), 3)<br>
a.histogram(Array(0.0, 3.0, 8.0))<br>
res14: Array[Long] = Array(5, 3)<br>
            <br>
val a = sc.parallelize(List(9.1, 1.0, 1.2, 2.1, 1.3, 5.0, 2.0, 2.1,
7.4, 7.5, 7.6, 8.8, 10.0, 8.9, 5.5), 3)<br>
a.histogram(Array(0.0, 5.0, 10.0))<br>
res1: Array[Long] = Array(6, 9)<br>
            <br>
a.histogram(Array(0.0, 5.0, 10.0, 15.0))<br>
res1: Array[Long] = Array(6, 8, 1)</td>
          </tr>
        </tbody>
      </table>
      </div>
      <br>
      <br>
      <hr style="width: 100%; height: 2px;"><br>
      <a name="id"></a><br>
      <br>
      <big><big><span style="font-weight: bold;">id</span></big></big><br>
      <br>
Retrieves the ID which has been assigned to the RDD by its device
context.<br>
      <br>
      <span style="font-weight: bold;">Listing Variants</span><br>
      <br>
      <div style="margin-left: 40px;">val id: Int</div>
      <br>
      <span style="font-weight: bold;">Example<br>
      <br>
      </span>
      <div style="margin-left: 40px;">
      <table style="text-align: left; width: 586px; height: 54px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top; background-color: rgb(242, 242, 242);">val
y = sc.parallelize(1 to 10, 10)<br>
y.id<br>
res16: Int = 19</td>
          </tr>
        </tbody>
      </table>
      </div>
      <br>
      <br>
      <br>
      <hr style="width: 100%; height: 2px;"><a name="intersection"></a><br>
      <br>
      <big><big><span style="font-weight: bold;">intersection</span></big></big><br>
      <br>
Returns the elements in the two RDDs which are the same.<br>
      <br>
      <span style="font-weight: bold;">Listing Variants</span><br>
      <br>
      <div style="margin-left: 40px;">def intersection(other: RDD[T],
numPartitions: Int): RDD[T]<br>
def intersection(other: RDD[T], partitioner: Partitioner)(implicit ord:
Ordering[T] = null): RDD[T]<br>
def intersection(other: RDD[T]): RDD[T]<br>
      </div>
      <br>
      <span style="font-weight: bold;">Example<br>
      <br>
      </span>
      <table style="text-align: left; width: 611px; height: 28px; margin-left: 40px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top;">val x = sc.parallelize(1
to 20)<br>
val y = sc.parallelize(10 to 30)<br>
val z = x.intersection(y)<br>
            <br>
z.collect<br>
res74: Array[Int] = Array(16, 12, 20, 13, 17, 14, 18, 10, 19, 15, 11)<br>
            </td>
          </tr>
        </tbody>
      </table>
      <br>
      <br>
      <br>
      <hr style="width: 100%; height: 2px;"><br>
      <a name="isCheckpointed"></a><br>
      <br>
      <big><big><span style="font-weight: bold;">isCheckpointed</span></big></big><br>
      <br>
Indicates whether the RDD has been checkpointed. The flag will only
raise once the checkpoint has really been created.<br>
      <br>
      <span style="font-weight: bold;">Listing Variants</span><br>
      <br>
      <div style="margin-left: 40px;">def isCheckpointed: Boolean</div>
      <br>
      <span style="font-weight: bold;">Example</span><br>
      <br>
      <div style="margin-left: 40px;">
      <table style="text-align: left; width: 586px; height: 54px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top; background-color: rgb(242, 242, 242);">sc.setCheckpointDir("/home/cloudera/Documents")<br>
c.isCheckpointed<br>
res6: Boolean = false<br>
            <br>
c.checkpoint<br>
c.isCheckpointed<br>
res8: Boolean = false<br>
            <br>
c.collect<br>
c.isCheckpointed<br>
res9: Boolean = true</td>
          </tr>
        </tbody>
      </table>
      </div>
      <br>
      <br>
      <hr style="width: 100%; height: 2px;"><br>
      <a name="iterator"></a><br>
      <br>
      <big><big><span style="font-weight: bold;">iterator</span></big></big><br>
      <br>
Returns a compatible iterator object for a partition of this RDD. This
function should never be called directly.<br>
      <br>
      <span style="font-weight: bold;">Listing Variants</span><br>
      <br>
      <div style="margin-left: 40px;">final def iterator(split:
Partition, context: TaskContext): Iterator[T]<br>
      </div>
      <span style="font-weight: bold;"><br>
      <br>
      </span>
      <hr style="width: 100%; height: 2px;"><span style="font-weight: bold;"><br>
      <a name="join"></a><br>
      <br>
      </span><big><big><span style="font-weight: bold;">join<small>
[Pair]</small></span></big></big><br>
      <br>
Performs an inner join using two key-value RDDs. Please note that the
keys must be generally comparable to make this work.<br>
      <br>
      <span style="font-weight: bold;">Listing Variants</span><br>
      <br>
      <div style="margin-left: 40px;">def join[W](other: RDD[(K, W)]):
RDD[(K, (V, W))]<br>
def join[W](other: RDD[(K, W)], numPartitions: Int): RDD[(K, (V, W))]<br>
def join[W](other: RDD[(K, W)], partitioner: Partitioner): RDD[(K, (V,
W))]<br>
      </div>
      <span style="font-weight: bold;"><br>
      </span><span style="font-weight: bold;">Example</span><br>
      <br>
      <div style="margin-left: 40px;">
      <table style="text-align: left; width: 639px; height: 159px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top; background-color: rgb(242, 242, 242);">val
a = sc.parallelize(List("dog", "salmon", "salmon", "rat", "elephant"),
3)<br>
val b = a.keyBy(_.length)<br>
val c =
sc.parallelize(List("dog","cat","gnu","salmon","rabbit","turkey","wolf","bear","bee"),
3)<br>
val d = c.keyBy(_.length)<br>
b.join(d).collect<br>
            <br>res0:
Array[(Int, (String, String))] = Array((6,(salmon,salmon)),
(6,(salmon,rabbit)), (6,(salmon,turkey)), (6,(salmon,salmon)),
(6,(salmon,rabbit)), (6,(salmon,turkey)), (3,(dog,dog)), (3,(dog,cat)),
(3,(dog,gnu)), (3,(dog,bee)), (3,(rat,dog)), (3,(rat,cat)),
(3,(rat,gnu)), (3,(rat,bee)))</td>
          </tr>
        </tbody>
      </table>
      </div>
      <br>
      <hr style="width: 100%; height: 2px;"><br>
      <a name="keyBy"></a><br>
      <br>
      <big><big><span style="font-weight: bold;">keyBy</span></big></big><br>
      <br>
Constructs two-component tuples (key-value pairs) by applying a
function on each data item. The result of the function becomes the key
and the original data item becomes the value of the newly created
tuples.<br>
      <br>
      <span style="font-weight: bold;">Listing Variants</span><br>
      <br>
      <div style="margin-left: 40px;">def keyBy[K](f: T =&gt; K):
RDD[(K, T)]<br>
      </div>
      <span style="font-weight: bold;"><br>
      </span><span style="font-weight: bold;">Example<br>
      <br>
      </span>
      <div style="margin-left: 40px;">
      <table style="text-align: left; width: 586px; height: 54px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top; background-color: rgb(242, 242, 242);">val
a = sc.parallelize(List("dog", "salmon", "salmon", "rat", "elephant"),
3)<br>
val b = a.keyBy(_.length)<br>
b.collect<br>
res26: Array[(Int, String)] = Array((3,dog), (6,salmon), (6,salmon),
(3,rat), (8,elephant))</td>
          </tr>
        </tbody>
      </table>
      </div>
      <br>
      <br>
      <hr style="width: 100%; height: 2px;"><br>
      <a name="keys"></a><br>
      <br>
      <big><big><span style="font-weight: bold;">keys <small>[Pair]</small></span></big></big><span style="font-weight: bold;"><br>
      <br>
      </span>Extracts the keys from all contained tuples and returns
them in a new RDD.<br>
      <br>
      <span style="font-weight: bold;">Listing Variants</span><br>
      <br>
      <div style="margin-left: 40px;">def keys: RDD[K]<br>
      </div>
      <span style="font-weight: bold;"><br>
      </span><span style="font-weight: bold;">Example</span><br>
      <br>
      <div style="margin-left: 40px;">
      <table style="text-align: left; width: 586px; height: 54px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top; background-color: rgb(242, 242, 242);">val
a = sc.parallelize(List("dog", "tiger", "lion", "cat", "panther",
"eagle"), 2)<br>
val b = a.map(x =&gt; (x.length, x))<br>
b.keys.collect<br>
res2: Array[Int] = Array(3, 5, 4, 3, 7, 5)</td>
          </tr>
        </tbody>
      </table>
      </div>
      <br>
      <br>
      <hr style="width: 100%; height: 2px;"><br>
      <a name="leftOuterJoin"></a><br>
      <br>
      <big><big><span style="font-weight: bold;">leftOuterJoin <small>[Pair]</small></span></big></big><br>
      <br>
Performs an left outer join using two key-value RDDs. Please note that
the keys must be generally comparable to make this work correctly.<br>
      <br>
      <span style="font-weight: bold;">Listing Variants</span><br>
      <br>
      <div style="margin-left: 40px;">def leftOuterJoin[W](other:
RDD[(K, W)]): RDD[(K, (V, Option[W]))]<br>
def leftOuterJoin[W](other: RDD[(K, W)], numPartitions: Int): RDD[(K,
(V, Option[W]))]<br>
def leftOuterJoin[W](other: RDD[(K, W)], partitioner: Partitioner):
RDD[(K, (V, Option[W]))]<br>
      </div>
      <span style="font-weight: bold;"><br>
      </span><span style="font-weight: bold;">Example</span><br>
      <br>
      <div style="margin-left: 40px;">
      <table style="text-align: left; width: 586px; height: 54px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top; background-color: rgb(242, 242, 242);">val
a = sc.parallelize(List("dog", "salmon", "salmon", "rat", "elephant"),
3)<br>
val b = a.keyBy(_.length)<br>
val c =
sc.parallelize(List("dog","cat","gnu","salmon","rabbit","turkey","wolf","bear","bee"),
3)<br>
val d = c.keyBy(_.length)<br>
b.leftOuterJoin(d).collect<br>
            <br>
res1: Array[(Int, (String, Option[String]))] =
Array((6,(salmon,Some(salmon))), (6,(salmon,Some(rabbit))),
(6,(salmon,Some(turkey))), (6,(salmon,Some(salmon))),
(6,(salmon,Some(rabbit))), (6,(salmon,Some(turkey))),
(3,(dog,Some(dog))), (3,(dog,Some(cat))), (3,(dog,Some(gnu))),
(3,(dog,Some(bee))), (3,(rat,Some(dog))), (3,(rat,Some(cat))),
(3,(rat,Some(gnu))), (3,(rat,Some(bee))), (8,(elephant,None)))</td>
          </tr>
        </tbody>
      </table>
      </div>
      <br>
      <br>
      <hr style="width: 100%; height: 2px;"><br>
      <a name="lookup"></a><br>
      <br>
      <big><big><span style="font-weight: bold;">lookup</span></big></big><br>
      <br>
Scans the RDD for all keys that match the provided value and returns
their values as a Scala sequence.<br>
      <br>
      <br>
      <span style="font-weight: bold;">Listing Variants</span><br>
      <br>
      <div style="margin-left: 40px;">def lookup(key: K): Seq[V]<br>
      </div>
      <span style="font-weight: bold;"><br>
      </span><span style="font-weight: bold;">Example</span><br>
      <br>
      <div style="margin-left: 40px;">
      <table style="text-align: left; width: 586px; height: 54px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top; background-color: rgb(242, 242, 242);">val
a = sc.parallelize(List("dog", "tiger", "lion", "cat", "panther",
"eagle"), 2)<br>
val b = a.map(x =&gt; (x.length, x))<br>
b.lookup(5)<br>
res0: Seq[String] = WrappedArray(tiger, eagle)</td>
          </tr>
        </tbody>
      </table>
      </div>
      <br>
      <br>
      <hr style="width: 100%; height: 2px;"><br>
      <a name="map"></a><br>
      <br>
      <big><big><span style="font-weight: bold;">map</span></big></big><br>
      <br>
Applies a transformation function on each item of the RDD and returns
the result as a new RDD.<br>
      <br>
      <br>
      <span style="font-weight: bold;">Listing Variants</span><br>
      <br>
      <div style="margin-left: 40px;">def map[U: ClassTag](f: T =&gt;
U): RDD[U]<br>
      </div>
      <span style="font-weight: bold;"><br>
      </span><span style="font-weight: bold;">Example</span><br>
      <div style="margin-left: 40px;">
      <table style="text-align: left; width: 586px; height: 54px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top; background-color: rgb(242, 242, 242);">val
a = sc.parallelize(List("dog", "salmon", "salmon", "rat", "elephant"),
3)<br>
val b = a.map(_.length)<br>
val c = a.zip(b)<br>
c.collect<br>
res0: Array[(String, Int)] = Array((dog,3), (salmon,6), (salmon,6),
(rat,3), (elephant,8))</td>
          </tr>
        </tbody>
      </table>
      </div>
      <br>
      <br>
      <hr style="width: 100%; height: 2px;"> <br>
      <a name="mapPartitions"></a><br>
      <br>
      <big><big><span style="font-weight: bold;">mapPartitions</span></big></big><br>
      <br>
This is a specialized map that is called only once for each partition.
The entire content of the respective partitions is available as a
sequential stream of values via the input argument (<span style="font-style: italic;">Iterarator[T]</span>). The custom function
must return yet another <span style="font-style: italic;">Iterator[U]</span>.
The combined result iterators are automatically converted into a new
RDD. Please note, that the tuples (3,4) and (6,7) are missing from the
following result due to the partitioning we chose.<br>
      <br>
      <br>
      <span style="font-weight: bold;">Listing Variants</span><br>
      <br>
      <div style="margin-left: 40px;">def mapPartitions[U: ClassTag](f:
Iterator[T] =&gt; Iterator[U], preservesPartitioning: Boolean = false):
RDD[U]<br>
      </div>
      <span style="font-weight: bold;"><br>
      </span><span style="font-weight: bold;">Example 1</span><br>
      <br>
      <div style="margin-left: 40px;">
      <table style="text-align: left; width: 586px; height: 54px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top; background-color: rgb(242, 242, 242);">val
a = sc.parallelize(1 to 9, 3)<br>
def myfunc[T](iter: Iterator[T]) : Iterator[(T, T)] = {<br>
&nbsp; var res = List[(T, T)]()<br>
&nbsp; var pre = iter.next<br>
&nbsp; while (iter.hasNext)<br>
&nbsp; {<br>
&nbsp;&nbsp;&nbsp; val cur = iter.next;<br>
&nbsp;&nbsp;&nbsp; res .::= (pre, cur)<br>
&nbsp;&nbsp;&nbsp; pre = cur;<br>
&nbsp; }<br>
&nbsp; res.iterator<br>
}<br>
a.mapPartitions(myfunc).collect<br>
res0: Array[(Int, Int)] = Array((2,3), (1,2), (5,6), (4,5), (8,9),
(7,8))</td>
          </tr>
        </tbody>
      </table>
      </div>
      <br>
      <span style="font-weight: bold;">Example 2</span><br>
      <br>
      <div style="margin-left: 40px;">
      <table style="text-align: left; width: 586px; height: 54px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top; background-color: rgb(242, 242, 242);">val
x = sc.parallelize(List(1, 2, 3, 4, 5, 6, 7, 8, 9,10),
3)<br>
def myfunc(iter: Iterator[Int]) : Iterator[Int] = {<br>
&nbsp; var res = List[Int]()<br>
&nbsp; while (iter.hasNext) {<br>
&nbsp;&nbsp;&nbsp; val cur = iter.next;<br>
&nbsp;&nbsp;&nbsp; res = res :::
List.fill(scala.util.Random.nextInt(10))(cur)<br>
&nbsp; }<br>
&nbsp; res.iterator<br>
}<br>
x.mapPartitions(myfunc).collect<br>
// some of the number are not outputted at all. This is because the
random number generated for it is zero.<br>
res8: Array[Int] = Array(1, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4,
4, 4, 4, 4, 4, 4, 5, 7, 7, 7, 9, 9, 10)</td>
          </tr>
        </tbody>
      </table>
      </div>
      <br>
The above program can also be written using <span style="font-weight: bold;">flatMap</span> as follows.<br>
      <br>
      <span style="font-weight: bold;">Example 2 using flatmap<br>
      <br>
      </span>
      <div style="margin-left: 40px;">
      <table style="text-align: left; width: 586px; height: 54px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top; background-color: rgb(242, 242, 242);">val
x&nbsp; = sc.parallelize(1 to 10, 3)<br>
x.flatMap(List.fill(scala.util.Random.nextInt(10))(_)).collect<br>
            <br>
res1: Array[Int] = Array(1, 2, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5,
5, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9,
9, 10, 10, 10, 10, 10, 10, 10, 10)</td>
          </tr>
        </tbody>
      </table>
      </div>
      <br>
      <br>
      <hr style="width: 100%; height: 2px;"><br>
      <a name="mapPartitionsWithContext"></a><br>
      <br>
      <big><big><span style="font-weight: bold;">mapPartitionsWithContext</span></big></big>&nbsp;&nbsp;<span style="font-weight: bold;"> (deprecated and developer API)</span><br>
      <br>
Similar to <span style="font-style: italic;">mapPartitions</span>, but
allows accessing information about the processing state within the
mapper.<br>
      <br>
      <br>
      <span style="font-weight: bold;">Listing Variants</span><br>
      <br>
      <div style="margin-left: 40px;">def mapPartitionsWithContext[U:
ClassTag](f: (TaskContext, Iterator[T]) =&gt; Iterator[U],
preservesPartitioning: Boolean = false): RDD[U]<br>
      </div>
      <span style="font-weight: bold;"><br>
      </span><span style="font-weight: bold;">Example</span><br>
      <br>
      <div style="margin-left: 40px;">
      <table style="text-align: left; width: 586px; height: 54px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top; background-color: rgb(242, 242, 242);">val
a = sc.parallelize(1 to 9, 3)<br>
import org.apache.spark.TaskContext<br>
def myfunc(tc: TaskContext, iter: Iterator[Int]) : Iterator[Int] = {<br>
&nbsp; tc.addOnCompleteCallback(() =&gt; println(<br>
&nbsp;&nbsp;&nbsp; "Partition: "&nbsp;&nbsp;&nbsp;&nbsp; +
tc.partitionId +<br>
&nbsp;&nbsp;&nbsp; ", AttemptID: "&nbsp;&nbsp; +
tc.attemptId ))<br>
&nbsp; <br>
&nbsp; iter.toList.filter(_ % 2 == 0).iterator<br>
}<br>
a.mapPartitionsWithContext(myfunc).collect<br>
            <br>
14/04/01 23:05:48 INFO SparkContext: Starting job: collect at
&lt;console&gt;:20<br>
...<br>
14/04/01 23:05:48 INFO Executor: Running task ID 0<br>
Partition: 0, AttemptID: 0, Interrupted: false<br>
...<br>
14/04/01 23:05:48 INFO Executor: Running task ID 1<br>
14/04/01 23:05:48 INFO TaskSetManager: Finished TID 0 in 470 ms on
localhost (progress: 0/3)<br>
...<br>
14/04/01 23:05:48 INFO Executor: Running task ID 2<br>
14/04/01 23:05:48 INFO TaskSetManager: Finished TID 1 in 23 ms on
localhost (progress: 1/3)<br>
14/04/01 23:05:48 INFO DAGScheduler: Completed ResultTask(0, 1)<br>
            <br>
?<br>
res0: Array[Int] = Array(2, 6, 4, 8)</td>
          </tr>
        </tbody>
      </table>
      </div>
      <br>
      <br>
      <hr style="width: 100%; height: 2px;"><br>
      <a name="mapPartitionsWithIndex"></a><br>
      <br>
      <big><big><span style="font-weight: bold;">mapPartitionsWithIndex</span></big></big><br>
      <br>
Similar to <span style="font-style: italic;">mapPartitions</span>, but
takes two parameters. The first parameter is the index of the partition
and the second is an iterator through all the items within this
partition. The output is an iterator containing the list of items after
applying whatever transformation the function encodes.<br>
      <br>
      <br>
      <span style="font-weight: bold;">Listing Variants</span><br>
      <div style="margin-left: 40px;">def mapPartitionsWithIndex[U:
ClassTag](f: (Int, Iterator[T]) =&gt; Iterator[U],
preservesPartitioning: Boolean = false): RDD[U]<br>
      </div>
      <span style="font-weight: bold;"><br>
      </span><span style="font-weight: bold;"><br>
      </span><span style="font-weight: bold;">Example</span><br>
      <br>
      <div style="margin-left: 40px;">
      <table style="text-align: left; width: 586px; height: 54px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top; background-color: rgb(242, 242, 242);">val
x = sc.parallelize(List(1,2,3,4,5,6,7,8,9,10), 3)<br>
def myfunc(index: Int, iter: Iterator[Int]) : Iterator[String] = {<br>
&nbsp; iter.map(x =&gt; index + "," + x)<br>
}<br>
x.mapPartitionsWithIndex(myfunc).collect()<br>
res10: Array[String] = Array(0,1, 0,2, 0,3, 1,4, 1,5, 1,6, 2,7, 2,8,
2,9, 2,10)</td>
          </tr>
        </tbody>
      </table>
      </div>
      <br>
      <br>
      <hr style="width: 100%; height: 2px;"><br>
      <a name="mapPartitionsWithSplit"></a><br>
      <br>
      <big><big><span style="font-weight: bold;">mapPartitionsWithSplit</span></big></big><br>
      <br>
This method has been marked as deprecated in the API. So, you should
not use this method anymore. Deprecated methods will not be covered in
this document.<br>
      <br>
      <br>
      <span style="font-weight: bold;">Listing Variants</span><br>
      <div style="margin-left: 40px;">def mapPartitionsWithSplit[U:
ClassTag](f: (Int, Iterator[T]) =&gt; Iterator[U],
preservesPartitioning: Boolean = false): RDD[U]<span style="font-weight: bold;"><br>
      <br>
      <br>
      </span> </div>
      <span style="font-weight: bold;"> </span>
      <hr style="width: 100%; height: 2px;"><span style="font-weight: bold;"><br>
      <a name="mapValues"></a><br>
      <br>
      </span><big><big><span style="font-weight: bold;">mapValues <small>[Pair]</small></span></big></big><br>
      <br>
Takes the values of a RDD that consists of two-component tuples, and
applies the provided function to transform each value. Then, it forms
new two-component tuples using the key and the transformed value and
stores them in a new RDD.<br>
      <br>
      <br>
      <span style="font-weight: bold;">Listing Variants<br>
      <br>
      </span>
      <div style="margin-left: 40px;">def mapValues[U](f: V =&gt; U):
RDD[(K, U)]<br>
      </div>
      <span style="font-weight: bold;"><br>
      </span><span style="font-weight: bold;"></span><span style="font-weight: bold;">Example<br>
      <br>
      </span>
      <div style="margin-left: 40px;">
      <table style="text-align: left; width: 586px; height: 54px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top; background-color: rgb(242, 242, 242);">val
a = sc.parallelize(List("dog", "tiger", "lion", "cat", "panther",
"eagle"), 2)<br>
val b = a.map(x =&gt; (x.length, x))<br>
b.mapValues("x" + _ + "x").collect<br>
res5: Array[(Int, String)] = Array((3,xdogx), (5,xtigerx), (4,xlionx),
(3,xcatx), (7,xpantherx), (5,xeaglex))</td>
          </tr>
        </tbody>
      </table>
      </div>
      <br>
      <br>
      <hr style="width: 100%; height: 2px;"><br>
      <a name="mapWith"></a><br>
      <br>
      <big><big><span style="font-weight: bold;">mapWith</span></big></big>&nbsp;
      <span style="font-weight: bold;">(deprecated)</span><br>
      <br>
This is an extended version of <span style="font-style: italic;">map</span>.
It takes two function arguments. The first argument must conform to <span style="font-style: italic;">Int -&gt; T</span> and is executed once
per partition. It will map the partition index to some transformed
partition index of type <span style="font-style: italic;">T</span>.
This is where it is nice to do some kind of initialization code once
per partition. Like create a Random number generator object.
The second function must conform to <span style="font-style: italic;">(U,
T) -&gt; U</span>. <span style="font-style: italic;">T</span> is the
transformed partition index and <span style="font-style: italic;">U</span>
is a data item of the RDD. Finally the function has to return a
transformed data item of type <span style="font-style: italic;">U</span>.<br>
      <br>
      <br>
      <span style="font-weight: bold;">Listing Variants<br>
      <br>
      </span>
      <div style="margin-left: 40px;">def mapWith[A: ClassTag, U:
ClassTag](constructA: Int =&gt; A, preservesPartitioning: Boolean =
false)(f: (T, A) =&gt; U): RDD[U]<br>
      </div>
      <span style="font-weight: bold;"><br>
      </span><span style="font-weight: bold;"></span><span style="font-weight: bold;">Example<br>
      </span><br>
      <div style="margin-left: 40px;">
      <table style="text-align: left; width: 586px; height: 54px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top; background-color: rgb(242, 242, 242);">//
generates 9 random numbers less than 1000. <br>
val x = sc.parallelize(1 to 9, 3)<br>
x.mapWith(a =&gt; new scala.util.Random)((x, r) =&gt;
r.nextInt(1000)).collect<br>
res0: Array[Int] = Array(940, 51, 779, 742, 757, 982, 35, 800, 15)<br>
            <br>
val a = sc.parallelize(1 to 9, 3)<br>
val b = a.mapWith("Index:" + _)((a, b) =&gt; ("Value:" + a, b))<br>
b.collect<br>
res0: Array[(String, String)] = Array((Value:1,Index:0),
(Value:2,Index:0), (Value:3,Index:0), (Value:4,Index:1),
(Value:5,Index:1), (Value:6,Index:1), (Value:7,Index:2),
(Value:8,Index:2), (Value:9,Index:2)<br>
            <br>
            <br>
            </td>
          </tr>
        </tbody>
      </table>
      </div>
      <br>
      <br>
      <hr style="width: 100%; height: 2px;"><br>
      <a name="max"></a><br>
      <big><big><span style="font-weight: bold;">max</span></big></big><span style="font-weight: bold;"></span><br>
      <br>
Returns the largest element in the RDD<br>
      <br>
      <span style="font-weight: bold;">Listing Variants<br>
      <br>
      </span>
      <div style="margin-left: 40px;">def max()(implicit ord:
Ordering[T]): T<br>
      </div>
      <span style="font-weight: bold;"><br>
      </span><span style="font-weight: bold;"></span><span style="font-weight: bold;">Example<br>
      </span><br>
      <table style="text-align: left; width: 630px; height: 28px; margin-left: 40px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top;">val y = sc.parallelize(10
to 30)<br>
y.max<br>
res75: Int = 30<br>
            <br>
val a = sc.parallelize(List((10, "dog"), (3, "tiger"), (9, "lion"), (18, "cat")))<br>

a.max<br>

res6: (Int, String) = (18,cat)<br>
            </td>
          </tr>
        </tbody>
      </table>
      <br>
      <br>
      <hr style="width: 100%; height: 2px;"><br>
      <a name="mean"></a><br>
      <br>
      <big><big><span style="font-weight: bold;">mean <small>[Double]</small>,
meanApprox <small>[Double]</small></span></big></big><br>
      <br>
Calls <span style="font-style: italic;">stats</span> and extracts the
mean component. The approximate version of the function can finish
somewhat faster in some scenarios. However, it trades accuracy for
speed.<br>
      <br>
      <br>
      <span style="font-weight: bold;">Listing Variants<br>
      <br>
      </span>
      <div style="margin-left: 40px;">def mean(): Double<br>
def meanApprox(timeout: Long, confidence: Double = 0.95):
PartialResult[BoundedDouble]<br>
      </div>
      <span style="font-weight: bold;"><br>
      </span><span style="font-weight: bold;"></span><span style="font-weight: bold;">Example</span><br>
      <br>
      <div style="margin-left: 40px;">
      <table style="text-align: left; width: 586px; height: 54px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top; background-color: rgb(242, 242, 242);">val
a = sc.parallelize(List(9.1, 1.0, 1.2, 2.1, 1.3, 5.0, 2.0, 2.1, 7.4,
7.5, 7.6, 8.8, 10.0, 8.9, 5.5), 3)<br>
a.mean<br>
res0: Double = 5.3</td>
          </tr>
        </tbody>
      </table>
      </div>
      <br>
      <br>
      <hr style="width: 100%; height: 2px;"><a name="min"></a><br>
      <br>
      <big><big><span style="font-weight: bold;">min</span></big></big><br>
      <br>
Returns the smallest element in the RDD<br>
      <br>
      <span style="font-weight: bold;">Listing Variants<br>
      <br>
      </span>
      <div style="margin-left: 40px;">def min()(implicit ord:
Ordering[T]): T<br>
      </div>
      <span style="font-weight: bold;"><br>
      </span><span style="font-weight: bold;"></span><span style="font-weight: bold;">Example</span><br>
      <br>
      <table style="text-align: left; width: 637px; height: 28px; margin-left: 40px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top;">val y = sc.parallelize(10
to 30)<br>
y.min<br>
res75: Int = 10<br>
            <br>
            <br>
val a = sc.parallelize(List((10, "dog"), (3, "tiger"), (9, "lion"), (8, "cat")))<br>
a.min<br>
res4: (Int, String) = (3,tiger)<br>
            </td>
          </tr>
        </tbody>
      </table>
      <br>
      <br>
      <hr style="width: 100%; height: 2px;"><br>
      <a name="name"></a><br>
      <br>
      <big><big><span style="font-weight: bold;">name, setName</span></big></big><br>
      <br>
Allows a RDD to be tagged with a custom name.<br>
      <br>
      <span style="font-weight: bold;">Listing Variants<br>
      <br>
      </span>
      <div style="margin-left: 40px;">@transient var name: String<br>
def setName(_name: String)<br>
      </div>
      <span style="font-weight: bold;"><br>
      </span><span style="font-weight: bold;"></span><span style="font-weight: bold;">Example</span><br>
      <br>
      <div style="margin-left: 40px;">
      <table style="text-align: left; width: 586px; height: 54px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top; background-color: rgb(242, 242, 242);">val
y = sc.parallelize(1 to 10, 10)<br>
y.name<br>
res13: String = null<br>
y.setName("Fancy RDD Name")<br>
y.name<br>
res15: String = Fancy RDD Name</td>
          </tr>
        </tbody>
      </table>
      </div>
      <br>
      <br>
      <hr style="width: 100%; height: 2px;"><br>
      <a name="partitionBy"></a><br>
      <br>
      <big><big><span style="font-weight: bold;">partitionBy <small>[Pair]</small></span></big></big><br>
      <br>
Repartitions as key-value RDD using its keys. The partitioner
implementation can be supplied as the first argument.<br>
      <br>
      <span style="font-weight: bold;">Listing Variants<br>
      <br>
      </span>
      <div style="margin-left: 40px;">def partitionBy(partitioner:
Partitioner): RDD[(K, V)]<br>
      </div>
      <span style="font-weight: bold;"><br>
      <br>
      </span>
      <hr style="width: 100%; height: 2px;"><span style="font-weight: bold;"><br>
      <a name="partitioner"></a><br>
      <br>
      </span><big><big><span style="font-weight: bold;">partitioner </span></big></big><br>
      <br>
Specifies a function pointer to the default partitioner that will be
used for <span style="font-style: italic;">groupBy</span>, <span style="font-style: italic;">subtract</span>, <span style="font-style: italic;">reduceByKey</span> (from <span style="font-style: italic;">PairedRDDFunctions</span>), etc. functions.<br>
      <br>
      <span style="font-weight: bold;">Listing Variants<br>
      <br>
      </span>
      <div style="margin-left: 40px;">@transient val partitioner:
Option[Partitioner]</div>
      <br>
      <br>
      <hr style="width: 100%; height: 2px;"><br>
      <a name="partitions"></a><br>
      <br>
      <br>
      <big><big><span style="font-weight: bold;">partitions </span></big></big><br>
      <br>
Returns an array of the partition objects associated with this RDD.<br>
      <br>
      <span style="font-weight: bold;">Listing Variants<br>
      <br>
      </span>
      <div style="margin-left: 40px;">final def partitions:
Array[Partition]</div>
      <br>
      <br>
      <span style="font-weight: bold;">Example<br>
      <br>
      </span>
      <div style="margin-left: 40px;">
      <table style="text-align: left; width: 586px; height: 54px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top; background-color: rgb(242, 242, 242);">val
b = sc.parallelize(List("Gnu", "Cat", "Rat", "Dog", "Gnu", "Rat"), 2)<br>
b.partitions<br>
res48: Array[org.apache.spark.Partition] =
Array(org.apache.spark.rdd.ParallelCollectionPartition@18aa,
org.apache.spark.rdd.ParallelCollectionPartition@18ab)</td>
          </tr>
        </tbody>
      </table>
      </div>
      <br>
      <br>
      <hr style="width: 100%; height: 2px;"><br>
      <a name="persist"></a><br>
      <br>
      <big><big><span style="font-weight: bold;">persist, cache </span></big></big><br>
      <br>
These functions can be used to adjust the storage level of a RDD. When
freeing up memory, Spark will use the storage level identifier to
decide which partitions should be kept. The parameterless variants <span style="font-style: italic;">persist()</span> and <span style="font-style: italic;">cache()</span> are just abbreviations for <span style="font-style: italic;">persist(StorageLevel.MEMORY_ONLY)</span>. <span style="font-style: italic;">(Warning: Once the storage level has been
changed, it cannot be changed again!)</span><br>
      <br>
      <span style="font-weight: bold;">Listing Variants<br>
      <br>
      </span>
      <div style="margin-left: 40px;">def cache(): RDD[T]<br>
def persist(): RDD[T]<br>
def persist(newLevel: StorageLevel): RDD[T]</div>
      <br>
      <br>
      <span style="font-weight: bold;">Example<br>
      </span><br>
      <div style="margin-left: 40px;">
      <table style="text-align: left; width: 586px; height: 54px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top; background-color: rgb(242, 242, 242);">val
c = sc.parallelize(List("Gnu", "Cat", "Rat", "Dog", "Gnu", "Rat"), 2)<br>
c.getStorageLevel<br>
res0: org.apache.spark.storage.StorageLevel = StorageLevel(false,
false, false, false, 1)<br>
c.cache<br>
c.getStorageLevel<br>
res2: org.apache.spark.storage.StorageLevel = StorageLevel(false, true,
false, true, 1)</td>
          </tr>
        </tbody>
      </table>
      </div>
      <br>
      <br>
      <hr style="width: 100%; height: 2px;"><br>
      <a name="pipe"></a><br>
      <br>
      <big><big><span style="font-weight: bold;">pipe </span></big></big><br>
      <br>
Takes the RDD data of each partition and sends it via stdin to a
shell-command. The resulting output of the command is captured and
returned as a RDD of string values.<br>
      <br>
      <span style="font-weight: bold;">Listing Variants<br>
      <br>
      </span>
      <div style="margin-left: 40px;">def pipe(command: String):
RDD[String]<br>
def pipe(command: String, env: Map[String, String]): RDD[String]<br>
def pipe(command: Seq[String], env: Map[String, String] = Map(),
printPipeContext: (String =&gt; Unit) =&gt; Unit = null,
printRDDElement: (T, String =&gt; Unit) =&gt; Unit = null): RDD[String]</div>
      <br>
      <br>
      <span style="font-weight: bold;">Example</span><br>
      <br>
      <div style="margin-left: 40px;">
      <table style="text-align: left; width: 586px; height: 54px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top; background-color: rgb(242, 242, 242);">val
a = sc.parallelize(1 to 9, 3)<br>
a.pipe("head -n 1").collect<br>
res2: Array[String] = Array(1, 4, 7)</td>
          </tr>
        </tbody>
      </table>
      </div>
      <br>
      <br>
      <hr style="width: 100%; height: 2px;"><big><big><span style="font-weight: bold;"> <a name="randomSplit"></a><br>
randomSplit </span></big></big><br>
      <br>
Randomly splits an RDD into multiple smaller RDDs according to a
weights Array which specifies the percentage of the total data elements
that is assigned to each smaller RDD. Note the actual size of each
smaller RDD is only approximately equal to the percentages specified by
the weights Array. The second example below shows the number of items
in each smaller RDD does not exactly match the weights Array. &nbsp; A
random optional seed can be specified. This function is useful for
spliting data into a training set and a testing set for machine
learning.<br>
      <br>
      <span style="font-weight: bold;">Listing Variants<br>
      <br>
      </span>
      <div style="margin-left: 40px;">def randomSplit(weights:
Array[Double], seed: Long = Utils.random.nextLong): Array[RDD[T]]</div>
      <br>
      <br>
      <span style="font-weight: bold;">Example</span><br>
      <big><big><span style="font-weight: bold;"><br>
      </span></big></big>
      <table style="text-align: left; width: 602px; height: 28px; margin-left: 40px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top;">val y = sc.parallelize(1
to 10)<br>
val splits = y.randomSplit(Array(0.6, 0.4), seed = 11L)<br>
val training = splits(0)<br>
val test = splits(1)<br>
training.collect<br>
res:85 Array[Int] = Array(1, 4, 5, 6, 8, 10)<br>
test.collect<br>
res86: Array[Int] = Array(2, 3, 7, 9)<br>
            <br>
val y = sc.parallelize(1 to 10)<br>
val splits = y.randomSplit(Array(0.1, 0.3, 0.6))<br>
            <br>
val rdd1 = splits(0)<br>
val rdd2 = splits(1)<br>
val rdd3 = splits(2)<br>
            <br>
rdd1.collect<br>
res87: Array[Int] = Array(4, 10)<br>
rdd2.collect<br>
res88: Array[Int] = Array(1, 3, 5, 8)<br>
rdd3.collect<br>
res91: Array[Int] = Array(2, 6, 7, 9)<br>
            </td>
          </tr>
        </tbody>
      </table>
      <big><big><span style="font-weight: bold;"><br>
      </span></big></big>
      <hr style="width: 100%; height: 2px;"><big><big><span style="font-weight: bold;"><br>
      <a name="reduce"></a><br>
reduce </span></big></big><br>
      <br>
This function provides the well-known <span style="font-style: italic;">reduce</span>
functionality in Spark. Please note that any function <span style="font-style: italic;">f</span> you provide, should be
commutative in order to generate reproducible results.<br>
      <br>
      <span style="font-weight: bold;">Listing Variants<br>
      <br>
      </span>
      <div style="margin-left: 40px;">def reduce(f: (T, T) =&gt; T): T</div>
      <br>
      <br>
      <span style="font-weight: bold;">Example</span><br>
      <br>
      <div style="margin-left: 40px;">
      <table style="text-align: left; width: 586px; height: 54px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top; background-color: rgb(242, 242, 242);">val
a = sc.parallelize(1 to 100, 3)<br>
a.reduce(_ + _)<br>
res41: Int = 5050</td>
          </tr>
        </tbody>
      </table>
      </div>
      <br>
      <br>
      <hr style="width: 100%; height: 2px;"><br>
      <a name="reduceByKey"></a><br>
      <br>
      <br>
      <big><big><span style="font-weight: bold;">reduceByKey <small>[Pair]</small>,&nbsp;
reduceByKeyLocally <small>[Pair],</small> reduceByKeyToDriver <small>[Pair]</small></span></big></big><br>
      <br>
This function provides the well-known <span style="font-style: italic;">reduce</span>
functionality in Spark. Please note that any function <span style="font-style: italic;">f</span> you provide, should be
commutative in order to generate reproducible results.<br>
      <br>
      <span style="font-weight: bold;">Listing Variants<br>
      <br>
      </span>
      <div style="margin-left: 40px;">def reduceByKey(func: (V, V)
=&gt; V): RDD[(K, V)]<br>
def reduceByKey(func: (V, V) =&gt; V, numPartitions: Int): RDD[(K, V)]<br>
def reduceByKey(partitioner: Partitioner, func: (V, V) =&gt; V):
RDD[(K, V)]<br>
def reduceByKeyLocally(func: (V, V) =&gt; V): Map[K, V]<br>
def reduceByKeyToDriver(func: (V, V) =&gt; V): Map[K, V]</div>
      <br>
      <br>
      <span style="font-weight: bold;">Example</span><br>
      <br>
      <div style="margin-left: 40px;">
      <table style="text-align: left; width: 586px; height: 54px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top; background-color: rgb(242, 242, 242);">val
a = sc.parallelize(List("dog", "cat", "owl", "gnu", "ant"), 2)<br>
val b = a.map(x =&gt; (x.length, x))<br>
b.reduceByKey(_ + _).collect<br>
res86: Array[(Int, String)] = Array((3,dogcatowlgnuant))<br>
            <br>
val a = sc.parallelize(List("dog", "tiger", "lion", "cat", "panther",
"eagle"), 2)<br>
val b = a.map(x =&gt; (x.length, x))<br>
b.reduceByKey(_ + _).collect<br>
res87: Array[(Int, String)] = Array((4,lion), (3,dogcat), (7,panther),
(5,tigereagle))</td>
          </tr>
        </tbody>
      </table>
      </div>
      <br>
      <hr style="width: 100%; height: 2px;"><br>
      <a name="repartition"></a><br>
      <br>

      <big><big><span style="font-weight: bold;">repartition</span></big></big><br>

      <br>
This function changes the number of partitions to the number specified by the numPartitions parameter  <br>

      <br>

      <span style="font-weight: bold;">Listing Variants<br>
      <br>
      </span>
      
      <div style="margin-left: 40px;">def repartition(numPartitions: Int)(implicit ord: Ordering[T] = null): RDD[T]</div>

      <br>

      <br>

      <span style="font-weight: bold;">Example</span><br>
      <br>
      <table style="text-align: left; width: 631px; height: 24px; margin-left: 40px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top;">val rdd = sc.parallelize(List(1, 2, 10, 4, 5, 2, 1, 1, 1), 3)<br>
rdd.partitions.length<br>
res2: Int = 3<br>
val rdd2&nbsp; = rdd.repartition(5)<br>
rdd2.partitions.length<br>
res6: Int = 5<br>
            </td>
          </tr>
        </tbody>
      </table>
      <br>
      <br>
      <hr style="width: 100%; height: 2px;"><br>
      <a name="repartitionAndSortWithinPartitions"></a><br>
      <br>
      <br>


      <big><big><span style="font-weight: bold;">repartitionAndSortWithinPartitions</span></big></big> [Ordered]<br>


      <br>
Repartition the RDD according to the given partitioner and, within each resulting partition, sort records by their keys.<br>


      <br>


      <span style="font-weight: bold;">Listing Variants<br>
      <br>
      </span>
      
      
      <div style="margin-left: 40px;">def repartitionAndSortWithinPartitions(partitioner: Partitioner): RDD[(K, V)]</div>


      <br>


      <br>


      <span style="font-weight: bold;">Example</span><br>
      <br>
      <table style="text-align: left; width: 683px; margin-left: 40px; height: 23px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top;">// first we will do range partitioning which is not sorted<br>
val randRDD = sc.parallelize(List( (2,"cat"), (6, "mouse"),(7, "cup"), (3, "book"), (4, "tv"), (1, "screen"), (5, "heater")), 3)<br>
val rPartitioner = new org.apache.spark.RangePartitioner(3, randRDD)<br>
val partitioned = randRDD.partitionBy(rPartitioner)<br>
def myfunc(index: Int, iter: Iterator[(Int, String)]) : Iterator[String] = {<br>
&nbsp; iter.map(x =&gt; "[partID:" +&nbsp; index + ", val: " + x + "]")<br>
}<br>
partitioned.mapPartitionsWithIndex(myfunc).collect<br>
            <br>
res0: Array[String] = Array([partID:0, val: (2,cat)], [partID:0, val:
(3,book)], [partID:0, val: (1,screen)], [partID:1, val: (4,tv)],
[partID:1, val: (5,heater)], [partID:2, val: (6,mouse)], [partID:2,
val: (7,cup)])<br>
            <br>
            <br>
// now lets repartition but this time have it sorted<br>
val partitioned = randRDD.repartitionAndSortWithinPartitions(rPartitioner)<br>
def myfunc(index: Int, iter: Iterator[(Int, String)]) : Iterator[String] = {<br>
&nbsp; iter.map(x =&gt; "[partID:" +&nbsp; index + ", val: " + x + "]")<br>
}<br>
partitioned.mapPartitionsWithIndex(myfunc).collect<br>
            <br>
res1: Array[String] = Array([partID:0, val: (1,screen)], [partID:0,
val: (2,cat)], [partID:0, val: (3,book)], [partID:1, val: (4,tv)],
[partID:1, val: (5,heater)], [partID:2, val: (6,mouse)], [partID:2,
val: (7,cup)])<br>
            </td>
          </tr>
        </tbody>
      </table>
      <br>
      <br>
      <br>
      <br>
<br>
      
      <hr style="width: 100%; height: 2px;"><br>
<br>
      <a name="rightOuterJoin"></a><br>
      <br>
      <br>
      <span style="font-weight: bold;"></span><big><big><span style="font-weight: bold;">rightOuterJoin <small>[Pair]</small></span></big></big><br>
      <br>
Performs an right outer join using two key-value RDDs. Please note that
the keys must be generally comparable to make this work correctly.<br>
      <br>
      <span style="font-weight: bold;">Listing Variants<br>
      <br>
      </span>
      <div style="margin-left: 40px;">def rightOuterJoin[W](other:
RDD[(K, W)]): RDD[(K, (Option[V], W))]<br>
def rightOuterJoin[W](other: RDD[(K, W)], numPartitions: Int): RDD[(K,
(Option[V], W))]<br>
def rightOuterJoin[W](other: RDD[(K, W)], partitioner: Partitioner):
RDD[(K, (Option[V], W))]</div>
      <br>
      <br>
      <span style="font-weight: bold;">Example</span><br>
      <br>
      <div style="margin-left: 40px;">
      <table style="text-align: left; width: 586px; height: 54px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top; background-color: rgb(242, 242, 242);">val
a = sc.parallelize(List("dog", "salmon", "salmon", "rat", "elephant"),
3)<br>
val b = a.keyBy(_.length)<br>
val c =
sc.parallelize(List("dog","cat","gnu","salmon","rabbit","turkey","wolf","bear","bee"),
3)<br>
val d = c.keyBy(_.length)<br>
b.rightOuterJoin(d).collect<br>
            <br>
res2: Array[(Int, (Option[String], String))] =
Array((6,(Some(salmon),salmon)), (6,(Some(salmon),rabbit)),
(6,(Some(salmon),turkey)), (6,(Some(salmon),salmon)),
(6,(Some(salmon),rabbit)), (6,(Some(salmon),turkey)),
(3,(Some(dog),dog)), (3,(Some(dog),cat)), (3,(Some(dog),gnu)),
(3,(Some(dog),bee)), (3,(Some(rat),dog)), (3,(Some(rat),cat)),
(3,(Some(rat),gnu)), (3,(Some(rat),bee)), (4,(None,wolf)),
(4,(None,bear)))</td>
          </tr>
        </tbody>
      </table>
      </div>
      <br>
      <br>
      <hr style="width: 100%; height: 2px;"><br>
      <a name="sample"></a><br>
      <br>
      <br>
      <big><big><span style="font-weight: bold;">sample</span></big></big><br>
      <br>
Randomly selects a fraction of the items of a RDD and returns them in a
new RDD.<br>
      <br>
      <span style="font-weight: bold;">Listing Variants<br>
      <br>
      </span>
      <div style="margin-left: 40px;">def sample(withReplacement:
Boolean, fraction: Double, seed: Int): RDD[T]</div>
      <br>
      <br>
      <span style="font-weight: bold;">Example</span><br>
      <br>
      <div style="margin-left: 40px;">
      <table style="text-align: left; width: 586px; height: 54px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top; background-color: rgb(242, 242, 242);">val
a = sc.parallelize(1 to 10000, 3)<br>
a.sample(false, 0.1, 0).count<br>
res24: Long = 960<br>
            <br>
a.sample(true, 0.3, 0).count<br>
res25: Long = 2888<br>
            <br>
a.sample(true, 0.3, 13).count<br>
res26: Long = 2985</td>
          </tr>
        </tbody>
      </table>
      </div>
      <br>
      <br>
      <hr style="width: 100%; height: 2px;"><br>
      <a name="sampleByKey"></a><br>
      <br>
      <br>

      <big><big><span style="font-weight: bold;">sampleByKey</span></big></big> [Pair]<br>

      <br>

Randomly samples the key value pair RDD according to the fraction of each key you want to appear in the final RDD.<br>

      <br>

      <span style="font-weight: bold;">Listing Variants<br>
      <br>
      </span>
      
      <div style="margin-left: 40px;">def sampleByKey(withReplacement: Boolean, fractions: Map[K, Double], seed: Long = Utils.random.nextLong): RDD[(K, V)]</div>

      <br>

      <br>
      <span style="font-weight: bold;">Example</span><br>

      <br>
      <table style="text-align: left; width: 640px; margin-left: 40px; height: 24px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top;">val randRDD = sc.parallelize(List( (7,"cat"), (6, "mouse"),(7, "cup"), (6, "book"), (7, "tv"), (6, "screen"), (7, "heater")))<br>
val sampleMap = List((7, 0.4), (6, 0.6)).toMap<br>
randRDD.sampleByKey(false, sampleMap,42).collect<br>
            <br>
res6: Array[(Int, String)] = Array((7,cat), (6,mouse), (6,book), (6,screen), (7,heater))<br>
            </td>
          </tr>
        </tbody>
      </table>
      <br>
      <br>
      <hr style="width: 100%; height: 2px;"><a name="sampleByKeyExact"></a><br>
      <br>
      <br>


      <big><big><span style="font-weight: bold;">sampleByKeyExact</span></big></big> [Pair, experimental]<br>


      <br>
This is labelled as experimental and so we do not document it.<br>


      <br>


      <span style="font-weight: bold;">Listing Variants<br>
      <br>
      </span>
      
      <div style="margin-left: 40px;">def sampleByKeyExact(withReplacement: Boolean, fractions: Map[K, Double], seed: Long = Utils.random.nextLong): RDD[(K, V)]<br>
      </div>


      <br>
      <br>
<br>
      <hr style="width: 100%; height: 2px;"><br>
      <a name="saveAsHadoopFile"></a><br>
      <br>
      <big><big><span style="font-weight: bold;">saveAsHadoopFile <small>[Pair]</small>,
saveAsHadoopDataset <small>[Pair]</small>, saveAsNewAPIHadoopFile <small>[Pair]</small></span></big></big><br>
      <br>
Saves the RDD in a Hadoop compatible format using any Hadoop
outputFormat class the user specifies.<br>
      <br>
      <span style="font-weight: bold;">Listing Variants<br>
      <br>
      </span>
      <div style="margin-left: 40px;">def saveAsHadoopDataset(conf:
JobConf)<br>
def saveAsHadoopFile[F &lt;: OutputFormat[K, V]](path: String)(implicit
fm: ClassTag[F])<br>
def saveAsHadoopFile[F &lt;: OutputFormat[K, V]](path: String, codec:
Class[_ &lt;: CompressionCodec]) (implicit fm: ClassTag[F])<br>
def saveAsHadoopFile(path: String, keyClass: Class[_], valueClass:
Class[_], outputFormatClass: Class[_ &lt;: OutputFormat[_, _]], codec:
Class[_ &lt;: CompressionCodec])<br>
def saveAsHadoopFile(path: String, keyClass: Class[_], valueClass:
Class[_], outputFormatClass: Class[_ &lt;: OutputFormat[_, _]], conf:
JobConf = new JobConf(self.context.hadoopConfiguration), codec:
Option[Class[_ &lt;: CompressionCodec]] = None)<br>
def saveAsNewAPIHadoopFile[F &lt;: NewOutputFormat[K, V]](path:
String)(implicit fm: ClassTag[F])<br>
def saveAsNewAPIHadoopFile(path: String, keyClass: Class[_],
valueClass: Class[_], outputFormatClass: Class[_ &lt;:
NewOutputFormat[_, _]], conf: Configuration =
self.context.hadoopConfiguration)</div>
      <br>
      <br>
      <hr style="width: 100%; height: 2px;"><br>
      <a name="saveAsObjectFile"></a><br>
      <br>
      <big><big><span style="font-weight: bold;">saveAsObjectFile</span></big></big><br>
      <br>
Saves the RDD in binary format.<br>
      <br>
      <span style="font-weight: bold;">Listing Variants<br>
      </span><br>
      <div style="margin-left: 40px;">def saveAsObjectFile(path: String)<br>
      </div>
      <br>
      <span style="font-weight: bold;">Example</span><br>
      <br>
      <div style="margin-left: 40px;">
      <table style="text-align: left; width: 586px; height: 54px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top; background-color: rgb(242, 242, 242);">val
x = sc.parallelize(1 to 100, 3)<br>
x.saveAsObjectFile("objFile")<br>
val y = sc.objectFile[Int]("objFile")<br>
y.collect<br>
res52: Array[Int] =&nbsp; Array[Int] = Array(1, 2, 3, 4, 5, 6, 7, 8, 9,
10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27,
28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45,
46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63,
64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81,
82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99,
100)</td>
          </tr>
        </tbody>
      </table>
      </div>
      <br>
      <br>
      <hr style="width: 100%; height: 2px;"><br>
      <a name="saveAsSequenceFile"></a><br>
      <br>
      <br>
      <big><big><span style="font-weight: bold;">saveAsSequenceFile <small>[SeqFile]</small></span></big></big><br>
      <br>
Saves the RDD as a Hadoop sequence file.<br>
      <br>
      <span style="font-weight: bold;">Listing Variants<br>
      </span><br>
      <div style="margin-left: 40px;">def saveAsSequenceFile(path:
String, codec: Option[Class[_ &lt;: CompressionCodec]] = None)<br>
      </div>
      <br>
      <span style="font-weight: bold;">Example</span><br>
      <br>
      <div style="margin-left: 40px;">
      <table style="text-align: left; width: 586px; height: 54px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top; background-color: rgb(242, 242, 242);">val
v = sc.parallelize(Array(("owl",3), ("gnu",4), ("dog",1), ("cat",2),
("ant",5)), 2)<br>
v.saveAsSequenceFile("hd_seq_file")<br>
14/04/19 05:45:43 INFO FileOutputCommitter: Saved output of task
'attempt_201404190545_0000_m_000001_191' to
file:/home/cloudera/hd_seq_file<br>
            <br>
[cloudera@localhost ~]$ ll ~/hd_seq_file<br>
total 8<br>
-rwxr-xr-x 1 cloudera cloudera 117 Apr 19 05:45 part-00000<br>
-rwxr-xr-x 1 cloudera cloudera 133 Apr 19 05:45 part-00001<br>
-rwxr-xr-x 1 cloudera cloudera&nbsp;&nbsp; 0 Apr 19 05:45 _SUCCESS</td>
          </tr>
        </tbody>
      </table>
      </div>
      <br>
      <hr style="width: 100%; height: 2px;"><br>
      <a name="saveAsTextFile"></a><br>
      <br>
      <big><big><span style="font-weight: bold;">saveAsTextFile</span></big></big><br>
      <br>
Saves the RDD as text files. One line at a time.<br>
      <br>
      <span style="font-weight: bold;">Listing Variants<br>
      </span><br>
      <div style="margin-left: 40px;">def saveAsTextFile(path: String)<br>
def saveAsTextFile(path: String, codec: Class[_ &lt;: CompressionCodec])<br>
      </div>
      <br>
      <span style="font-weight: bold;">Example without compression</span><br>
      <br>
      <div style="margin-left: 40px;">
      <table style="text-align: left; width: 586px; height: 54px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top; background-color: rgb(242, 242, 242);">val
a = sc.parallelize(1 to 10000, 3)<br>
a.saveAsTextFile("mydata_a")<br>
14/04/03 21:11:36 INFO FileOutputCommitter: Saved output of task
'attempt_201404032111_0000_m_000002_71' to
file:/home/cloudera/Documents/spark-0.9.0-incubating-bin-cdh4/bin/mydata_a<br>
            <br>
            <br>
[cloudera@localhost ~]$ head -n 5
~/Documents/spark-0.9.0-incubating-bin-cdh4/bin/mydata_a/part-00000<br>
1<br>
2<br>
3<br>
4<br>
5<br>
            <br>
// Produces 3 output files since we have created the a RDD with 3
partitions<br>
[cloudera@localhost ~]$ ll
~/Documents/spark-0.9.0-incubating-bin-cdh4/bin/mydata_a/<br>
-rwxr-xr-x 1 cloudera cloudera 15558 Apr&nbsp; 3 21:11 part-00000<br>
-rwxr-xr-x 1 cloudera cloudera 16665 Apr&nbsp; 3 21:11 part-00001<br>
-rwxr-xr-x 1 cloudera cloudera 16671 Apr&nbsp; 3 21:11 part-00002</td>
          </tr>
        </tbody>
      </table>
      </div>
      <br>
      <br>
      <span style="font-weight: bold;">Example with compression</span><br>
      <br>
      <div style="margin-left: 40px;">
      <table style="text-align: left; width: 586px; height: 54px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top; background-color: rgb(242, 242, 242);">import
org.apache.hadoop.io.compress.GzipCodec<br>
a.saveAsTextFile("mydata_b", classOf[GzipCodec])<br>
            <br>
[cloudera@localhost ~]$ ll
~/Documents/spark-0.9.0-incubating-bin-cdh4/bin/mydata_b/<br>
total 24<br>
-rwxr-xr-x 1 cloudera cloudera 7276 Apr&nbsp; 3 21:29 part-00000.gz<br>
-rwxr-xr-x 1 cloudera cloudera 6517 Apr&nbsp; 3 21:29 part-00001.gz<br>
-rwxr-xr-x 1 cloudera cloudera 6525 Apr&nbsp; 3 21:29 part-00002.gz<br>
            <br>
val x = sc.textFile("mydata_b")<br>
x.count<br>
res2: Long = 10000</td>
          </tr>
        </tbody>
      </table>
      </div>
      <br>
      <br>
      <span style="font-weight: bold;">Example writing into HDFS<br>
      <br>
      </span>
      <div style="margin-left: 40px;">
      <table style="text-align: left; width: 586px; height: 54px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top; background-color: rgb(242, 242, 242);">val
x = sc.parallelize(List(1,2,3,4,5,6,6,7,9,8,10,21), 3)<br>
x.saveAsTextFile("hdfs://localhost:8020/user/cloudera/test");<br>
            <br>
val sp = sc.textFile("hdfs://localhost:8020/user/cloudera/sp_data")<br>
sp.flatMap(_.split("
")).saveAsTextFile("hdfs://localhost:8020/user/cloudera/sp_x")</td>
          </tr>
        </tbody>
      </table>
      </div>
      <br>
      <br>
      <hr style="width: 100%; height: 2px;"><br>
      <a name="stats"></a><br>
      <br>
      <br>
      <big><big><span style="font-weight: bold;">stats <small>[Double]</small></span></big></big><br>
      <br>
Simultaneously computes the mean, variance and the standard deviation
of all values in the RDD.<br>
      <br>
      <span style="font-weight: bold;">Listing Variants<br>
      </span><br>
      <div style="margin-left: 40px;">def stats(): StatCounter<br>
      </div>
      <br>
      <span style="font-weight: bold;">Example<br>
      <br>
      </span>
      <div style="margin-left: 40px;">
      <table style="text-align: left; width: 586px; height: 54px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top; background-color: rgb(242, 242, 242);">val
x = sc.parallelize(List(1.0, 2.0, 3.0, 5.0, 20.0, 19.02, 19.29, 11.09,
21.0), 2)<br>
x.stats<br>
res16: org.apache.spark.util.StatCounter = (count: 9, mean: 11.266667,
stdev: 8.126859)</td>
          </tr>
        </tbody>
      </table>
      </div>
      <br>
      <br>
      <big><big><span style="font-weight: bold;"></span></big></big>
      <hr style="width: 100%; height: 2px;"><big><big><span style="font-weight: bold;"></span></big></big><big><big><span style="font-weight: bold;"><br>
      <a name="sortBy"></a><br>
sortBy</span></big></big><big><big><span style="font-weight: bold;"><br>
      </span></big></big><br>
This function sorts the input RDD's data and stores it in a new RDD.
The first parameter requires you to specify a function which&nbsp; maps
the input data into the key that you want to sortBy. The second
parameter (optional) specifies whether you want the data to be sorted
in ascending or descending order.<br>
      <br>
      <span style="font-weight: bold;">Listing Variants<br>
      </span><br>
      <div style="margin-left: 40px;">def sortBy[K](f: (T) &#8658; K,
ascending: Boolean = true, numPartitions: Int =
this.partitions.size)(implicit ord: Ordering[K], ctag: ClassTag[K]):
RDD[T]<br>
      </div>
      <br>
      <span style="font-weight: bold;">Example</span><br>
      <br>
      <big><big><span style="font-weight: bold;"><br>
      </span></big></big>
      <table style="text-align: left; width: 686px; height: 28px; margin-left: 40px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top;"><br>
val y = sc.parallelize(Array(5, 7, 1, 3, 2, 1))<br>
y.sortBy(c =&gt; c, true).collect<br>
res101: Array[Int] = Array(1, 1, 2, 3, 5, 7)<br>
            <br>
y.sortBy(c =&gt; c, false).collect<br>
res102: Array[Int] = Array(7, 5, 3, 2, 1, 1)<br>
            <br>
val z = sc.parallelize(Array(("H", 10), ("A", 26), ("Z", 1), ("L", 5)))<br>
z.sortBy(c =&gt; c._1, true).collect<br>
res109: Array[(String, Int)] = Array((A,26), (H,10), (L,5), (Z,1))<br>
            <br>
z.sortBy(c =&gt; c._2, true).collect<br>
res108: Array[(String, Int)] = Array((Z,1), (L,5), (H,10), (A,26))<br>
            </td>
          </tr>
        </tbody>
      </table>
      <big><big><span style="font-weight: bold;"><br>
      <br>
      </span></big></big>
      <hr style="width: 100%; height: 2px;"><big><big><span style="font-weight: bold;"><br>
      <a name="sortByKey"></a><br>
      <br>
sortByKey <small>[Ordered]</small></span></big></big><br>
      <br>
This function sorts the input RDD's data and stores it in a new RDD.
The output RDD is a shuffled RDD because it stores data that is output
by a reducer which has been shuffled. The implementation of this
function is actually very clever. First, it uses a range partitioner to
partition the data in ranges within the shuffled RDD. Then it sorts
these ranges individually with mapPartitions using standard sort
mechanisms.<br>
      <br>
      <span style="font-weight: bold;">Listing Variants<br>
      </span><br>
      <div style="margin-left: 40px;">def sortByKey(ascending: Boolean
= true, numPartitions: Int = self.partitions.size): RDD[P]<br>
      </div>
      <br>
      <span style="font-weight: bold;">Example</span><br>
      <br>
      <div style="margin-left: 40px;">
      <table style="text-align: left; width: 586px; height: 54px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top; background-color: rgb(242, 242, 242);">val
a = sc.parallelize(List("dog", "cat", "owl", "gnu", "ant"), 2)<br>
val b = sc.parallelize(1 to a.count.toInt, 2)<br>
val c = a.zip(b)<br>
c.sortByKey(true).collect<br>
res74: Array[(String, Int)] = Array((ant,5), (cat,2), (dog,1), (gnu,4),
(owl,3))<br>
c.sortByKey(false).collect<br>
res75: Array[(String, Int)] = Array((owl,3), (gnu,4), (dog,1), (cat,2),
(ant,5))<br>
            <br>
val a = sc.parallelize(1 to 100, 5)<br>
val b = a.cartesian(a)<br>
val c = sc.parallelize(b.takeSample(true, 5, 13), 2)<br>
val d = c.sortByKey(false)<br>
res56: Array[(Int, Int)] = Array((96,9), (84,76), (59,59), (53,65),
(52,4))</td>
          </tr>
        </tbody>
      </table>
      </div>
      <br>
      <br>
      <hr style="width: 100%; height: 2px;"><br>
      <a name="stdev"></a><br>
      <br>
      <big><big><span style="font-weight: bold;">stdev <small>[Double],
sampleStdev [Double]</small></span></big></big><br>
      <br>
Calls <span style="font-style: italic;">stats</span> and extracts
either <span style="font-style: italic;">stdev</span>-component or
corrected <span style="font-style: italic;">sampleStdev</span>-component.<br>
      <br>
      <span style="font-weight: bold;">Listing Variants<br>
      </span><br>
      <div style="margin-left: 40px;">def stdev(): Double<br>
def sampleStdev(): Double<br>
      </div>
      <br>
      <span style="font-weight: bold;">Example</span><br>
      <br>
      <div style="margin-left: 40px;">
      <table style="text-align: left; width: 586px; height: 54px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top; background-color: rgb(242, 242, 242);">val
d = sc.parallelize(List(0.0, 0.0, 0.0), 3)<br>
d.stdev<br>
res10: Double = 0.0<br>
d.sampleStdev<br>
res11: Double = 0.0<br>
            <br>
val d = sc.parallelize(List(0.0, 1.0), 3)<br>
d.stdev<br>
d.sampleStdev<br>
res18: Double = 0.5<br>
res19: Double = 0.7071067811865476<br>
            <br>
val d = sc.parallelize(List(0.0, 0.0, 1.0), 3)<br>
d.stdev<br>
res14: Double = 0.4714045207910317<br>
d.sampleStdev<br>
res15: Double = 0.5773502691896257</td>
          </tr>
        </tbody>
      </table>
      </div>
      <br>
      <br>
      <hr style="width: 100%; height: 2px;"><br>
      <a name="subtract"></a><br>
      <br>
      <big><big><span style="font-weight: bold;">subtract</span></big></big><br>
      <br>
Performs the well known standard set subtraction operation: A - B<br>
      <br>
      <span style="font-weight: bold;">Listing Variants<br>
      </span><br>
      <div style="margin-left: 40px;">def subtract(other: RDD[T]):
RDD[T]<br>
def subtract(other: RDD[T], numPartitions: Int): RDD[T]<br>
def subtract(other: RDD[T], p: Partitioner): RDD[T]<br>
      </div>
      <br>
      <span style="font-weight: bold;">Example</span><br>
      <br>
      <div style="margin-left: 40px;">
      <table style="text-align: left; width: 586px; height: 54px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top; background-color: rgb(242, 242, 242);">val
a = sc.parallelize(1 to 9, 3)<br>
val b = sc.parallelize(1 to 3, 3)<br>
val c = a.subtract(b)<br>
c.collect<br>
res3: Array[Int] = Array(6, 9, 4, 7, 5, 8)</td>
          </tr>
        </tbody>
      </table>
      </div>
      <br>
      <br>
      <hr style="width: 100%; height: 2px;"><br>
      <a name="subtractByKey"></a><br>
      <br>
      <br>
      <big><big><span style="font-weight: bold;">subtractByKey <small>[Pair]</small></span></big></big><br>
      <br>
Very similar to <span style="font-style: italic;">subtract</span>, but
instead of supplying a function, the key-component of each pair will be
automatically used as criterion for removing items from the first RDD.<br>
      <br>
      <span style="font-weight: bold;">Listing Variants<br>
      </span><br>
      <div style="margin-left: 40px;">def subtractByKey[W:
ClassTag](other: RDD[(K, W)]): RDD[(K, V)]<br>
def subtractByKey[W: ClassTag](other: RDD[(K, W)], numPartitions: Int):
RDD[(K, V)]<br>
def subtractByKey[W: ClassTag](other: RDD[(K, W)], p: Partitioner):
RDD[(K, V)]<br>
      </div>
      <br>
      <span style="font-weight: bold;">Example</span><br>
      <br>
      <div style="margin-left: 40px;">
      <table style="text-align: left; width: 586px; height: 54px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top; background-color: rgb(242, 242, 242);">val
a = sc.parallelize(List("dog", "tiger", "lion", "cat", "spider",
"eagle"), 2)<br>
val b = a.keyBy(_.length)<br>
val c = sc.parallelize(List("ant", "falcon", "squid"), 2)<br>
val d = c.keyBy(_.length)<br>
b.subtractByKey(d).collect<br>
res15: Array[(Int, String)] = Array((4,lion))</td>
          </tr>
        </tbody>
      </table>
      </div>
      <br>
      <br>
      <hr style="width: 100%; height: 2px;"><br>
      <a name="sum"></a><br>
      <br>
      <big><big><span style="font-weight: bold;">sum <small>[Double],
sumApprox [Double]</small></span></big></big><br>
      <br>
Computes the sum of all values contained in the RDD. The approximate
version of the function can finish somewhat faster in some scenarios.
However, it trades accuracy for speed.<br>
      <br>
      <br>
      <span style="font-weight: bold;">Listing Variants<br>
      </span><br>
      <div style="margin-left: 40px;">def sum(): Double<br>
def sumApprox(timeout: Long, confidence: Double = 0.95):
PartialResult[BoundedDouble]<br>
      </div>
      <br>
      <span style="font-weight: bold;">Example</span><br>
      <br>
      <div style="margin-left: 40px;">
      <table style="text-align: left; width: 586px; height: 54px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top; background-color: rgb(242, 242, 242);">val
x = sc.parallelize(List(1.0, 2.0, 3.0, 5.0, 20.0, 19.02, 19.29, 11.09,
21.0), 2)<br>
x.sum<br>
res17: Double = 101.39999999999999</td>
          </tr>
        </tbody>
      </table>
      </div>
      <br>
      <br>
      <hr style="width: 100%; height: 2px;"><br>
      <a name="take"></a><br>
      <br>
      <big><big><span style="font-weight: bold;">take</span></big></big><br>
      <br>
Extracts the first <span style="font-style: italic;">n</span> items of
the RDD and returns them as an array. <span style="font-style: italic;">(Note:
This sounds very easy, but it is actually quite a tricky problem for
the implementors of Spark because the items in question can be in many
different partitions.)</span><br>
      <br>
      <br>
      <span style="font-weight: bold;">Listing Variants<br>
      </span><br>
      <div style="margin-left: 40px;">def take(num: Int): Array[T]<br>
      </div>
      <br>
      <span style="font-weight: bold;">Example</span><br>
      <br>
      <div style="margin-left: 40px;">
      <table style="text-align: left; width: 586px; height: 54px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top; background-color: rgb(242, 242, 242);">val
b = sc.parallelize(List("dog", "cat", "ape", "salmon", "gnu"), 2)<br>
b.take(2)<br>
res18: Array[String] = Array(dog, cat)<br>
            <br>
val b = sc.parallelize(1 to 10000, 5000)<br>
b.take(100)<br>
res6: Array[Int] = Array(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14,
15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32,
33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,
51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68,
69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86,
87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100)</td>
          </tr>
        </tbody>
      </table>
      </div>
      <br>
      <br>
      <hr style="width: 100%; height: 2px;"><br>
      <a name="takeOrdered"></a><br>
      <br>
      <br>
      <big><big><span style="font-weight: bold;">takeOrdered</span></big></big><br>
      <br>
Orders the data items of the RDD using their inherent implicit ordering
function and returns the first <span style="font-style: italic;">n</span>
items as an array.<br>
      <br>
      <br>
      <span style="font-weight: bold;">Listing Variants<br>
      </span><br>
      <div style="margin-left: 40px;">def takeOrdered(num:
Int)(implicit ord: Ordering[T]): Array[T]<br>
      </div>
      <br>
      <span style="font-weight: bold;">Example</span><br>
      <br>
      <div style="margin-left: 40px;">
      <table style="text-align: left; width: 586px; height: 54px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top; background-color: rgb(242, 242, 242);">val
b = sc.parallelize(List("dog", "cat", "ape", "salmon", "gnu"), 2)<br>
b.takeOrdered(2)<br>
res19: Array[String] = Array(ape, cat)</td>
          </tr>
        </tbody>
      </table>
      </div>
      <br>
      <br>
      <hr style="width: 100%; height: 2px;"><br>
      <a name="takeSample"></a><br>
      <br>
      <big><big><span style="font-weight: bold;">takeSample</span></big></big><br>
      <br>
Behaves different from <span style="font-style: italic;">sample</span>
in the following respects:<br>
      <ul>
        <li>&nbsp; It will return an exact number of samples <span style="font-style: italic;">(Hint: 2nd parameter)</span></li>
        <li>&nbsp; It returns an Array instead of RDD.</li>
        <li>&nbsp; It internally randomizes the order of the items
returned.</li>
      </ul>
      <br>
      <span style="font-weight: bold;">Listing Variants<br>
      </span><br>
      <div style="margin-left: 40px;">def takeSample(withReplacement:
Boolean, num: Int, seed: Int): Array[T]<br>
      </div>
      <br>
      <span style="font-weight: bold;">Example</span><br>
      <br>
      <div style="margin-left: 40px;">
      <table style="text-align: left; width: 586px; height: 54px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top; background-color: rgb(242, 242, 242);">val
x = sc.parallelize(1 to 1000, 3)<br>
x.takeSample(true, 100, 1)<br>
res3: Array[Int] = Array(339, 718, 810, 105, 71, 268, 333, 360, 341,
300, 68, 848, 431, 449, 773, 172, 802, 339, 431, 285, 937, 301, 167,
69, 330, 864, 40, 645, 65, 349, 613, 468, 982, 314, 160, 675, 232, 794,
577, 571, 805, 317, 136, 860, 522, 45, 628, 178, 321, 482, 657, 114,
332, 728, 901, 290, 175, 876, 227, 130, 863, 773, 559, 301, 694, 460,
839, 952, 664, 851, 260, 729, 823, 880, 792, 964, 614, 821, 683, 364,
80, 875, 813, 951, 663, 344, 546, 918, 436, 451, 397, 670, 756, 512,
391, 70, 213, 896, 123, 858)</td>
          </tr>
        </tbody>
      </table>
      </div>
      <br>
      <br>
      <hr style="width: 100%; height: 2px;"><br>
      <a name="toDebugString"></a><br>
      <br>
      <big><big><span style="font-weight: bold;">toDebugString</span></big></big><br>
      <br>
Returns a string that contains debug information about the RDD and its
dependencies.<br>
      <br>
      <br>
      <span style="font-weight: bold;">Listing Variants<br>
      </span><br>
      <div style="margin-left: 40px;">def toDebugString: String<br>
      </div>
      <br>
      <span style="font-weight: bold;">Example</span><br>
      <br>
      <div style="margin-left: 40px;">
      <table style="text-align: left; width: 586px; height: 54px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top; background-color: rgb(242, 242, 242);">val
a = sc.parallelize(1 to 9, 3)<br>
val b = sc.parallelize(1 to 3, 3)<br>
val c = a.subtract(b)<br>
c.toDebugString<br>
res6: String = <br>
MappedRDD[15] at subtract at &lt;console&gt;:16 (3 partitions)<br>
&nbsp; SubtractedRDD[14] at subtract at &lt;console&gt;:16 (3
partitions)<br>
&nbsp;&nbsp;&nbsp; MappedRDD[12] at subtract at &lt;console&gt;:16 (3
partitions)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ParallelCollectionRDD[10] at parallelize
at &lt;console&gt;:12 (3 partitions)<br>
&nbsp;&nbsp;&nbsp; MappedRDD[13] at subtract at &lt;console&gt;:16 (3
partitions)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ParallelCollectionRDD[11] at parallelize
at &lt;console&gt;:12 (3 partitions)</td>
          </tr>
        </tbody>
      </table>
      </div>
      <br>
      <br>
      <hr style="width: 100%; height: 2px;"><br>
      <a name="toJavaRDD"></a><br>
      <br>
      <big><big><span style="font-weight: bold;">toJavaRDD</span></big></big><br>
      <br>
Embeds this RDD object within a JavaRDD object and returns it.<br>
      <br>
      <br>
      <span style="font-weight: bold;">Listing Variants<br>
      </span><br>
      <div style="margin-left: 40px;">def toJavaRDD() : JavaRDD[T]<br>
      </div>
      <br>
      <span style="font-weight: bold;">Example</span><br>
      <br>
      <div style="margin-left: 40px;">
      <table style="text-align: left; width: 586px; height: 54px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top; background-color: rgb(242, 242, 242);">val
c = sc.parallelize(List("Gnu", "Cat", "Rat", "Dog"), 2)<br>
c.toJavaRDD<br>
res3: org.apache.spark.api.java.JavaRDD[String] =
ParallelCollectionRDD[6] at parallelize at &lt;console&gt;:12</td>
          </tr>
        </tbody>
      </table>
      </div>
      <br>
<br>
      <hr style="width: 100%; height: 2px;">
      <br>
      <a name="toLocalIterator"></a><br>
      <br>

      <big><big><span style="font-weight: bold;">toLocalIterator</span></big></big><br>

      <br>
Converts the RDD into a scala iterator at the master node.<br>

      <br>

      <span style="font-weight: bold;">Listing Variants<br>
      </span><br>

      
      <div style="margin-left: 40px;">def toLocalIterator: Iterator[T]<br>
      </div>

      <br>

      <span style="font-weight: bold;">Example</span><br>
      <br>
      <table style="text-align: left; width: 627px; margin-left: 40px; height: 28px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top;">val z = sc.parallelize(List(1,2,3,4,5,6), 2)<br>
val iter = z.toLocalIterator<br>
            <br>
iter.next<br>
res51: Int = 1<br>
            <br>
iter.next<br>
res52: Int = 2<br>
            </td>
          </tr>
        </tbody>
      </table>
      <br>
      <br>
      <hr style="width: 100%; height: 2px;"><br>
      <a name="top"></a><br>
      <br>
      <big><big><span style="font-weight: bold;">top</span></big></big><br>
      <br>
Utilizes the implicit ordering of $T$ to determine the top $k$ values
and returns them as an array.<br>
      <br>
      <span style="font-weight: bold;">Listing Variants<br>
      </span><br>
      <div style="margin-left: 40px;">ddef top(num: Int)(implicit ord:
Ordering[T]): Array[T]<br>
      </div>
      <br>
      <span style="font-weight: bold;">Example</span><br>
      <br>
      <div style="margin-left: 40px;">
      <table style="text-align: left; width: 586px; height: 54px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top; background-color: rgb(242, 242, 242);">val
c = sc.parallelize(Array(6, 9, 4, 7, 5, 8), 2)<br>
c.top(2)<br>
res28: Array[Int] = Array(9, 8)</td>
          </tr>
        </tbody>
      </table>
      </div>
      <br>
      <hr style="width: 100%; height: 2px;"><br>
      <a name="toString"></a><br>
      <br>
      <big><big><span style="font-weight: bold;">toString</span></big></big><br>
      <br>
Assembles a human-readable textual description of the RDD.<br>
      <br>
      <br>
      <span style="font-weight: bold;">Listing Variants<br>
      </span><br>
      <div style="margin-left: 40px;">override def toString: String<br>
      </div>
      <br>
      <span style="font-weight: bold;">Example</span><br>
      <br>
      <div style="margin-left: 40px;">
      <table style="text-align: left; width: 586px; height: 54px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top; background-color: rgb(242, 242, 242);">val z = sc.parallelize(List(1,2,3,4,5,6), 2)<br>
z.toString<br>
res61: String = ParallelCollectionRDD[80] at parallelize at &lt;console&gt;:21<br>
            <br>
val randRDD = sc.parallelize(List( (7,"cat"), (6, "mouse"),(7, "cup"), (6, "book"), (7, "tv"), (6, "screen"), (7, "heater")))<br>
val sortedRDD = randRDD.sortByKey()<br>
sortedRDD.toString<br>
res64: String = ShuffledRDD[88] at sortByKey at &lt;console&gt;:23<br>
            <br>
</td>
          </tr>
        </tbody>
      </table>
      </div>
      <br>
      <hr style="width: 100%; height: 2px;"><br>
      <a name="treeAggregate"></a><br>
      <br>
      <br>
      <big><big><span style="font-weight: bold;">treeAggregate</span></big></big><br>

      <br>
Computes the same thing as aggregate, except it aggregates the elements
of the RDD in a multi-level tree pattern. Another difference is that it
does not use the initial value for the second reduce function
(combOp).&nbsp; By default a tree of depth 2 is used, but this can be
changed via the depth parameter.<br>

      <br>

      <br>

      <span style="font-weight: bold;">Listing Variants<br>
      </span><br>

      
      <div style="margin-left: 40px;">def treeAggregate[U](zeroValue: U)(seqOp: (U, T) &#8658; U, combOp: (U, U) &#8658; U, depth: Int = 2)(implicit arg0: ClassTag[U]): U<br>
      </div>

      <br>

      <span style="font-weight: bold;">Example</span><br>
      <br>
      <br>
      <table style="text-align: left; width: 713px; margin-left: 40px; height: 376px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top;">val z = sc.parallelize(List(1,2,3,4,5,6), 2)<br>
            <br>
// lets first print out the contents of the RDD with partition labels<br>
def myfunc(index: Int, iter: Iterator[(Int)]) : Iterator[String] = {<br>
&nbsp; iter.map(x =&gt; "[partID:" +&nbsp; index + ", val: " + x + "]")<br>
}<br>
            <br>
z.mapPartitionsWithIndex(myfunc).collect<br>
res28: Array[String] = Array([partID:0, val: 1], [partID:0, val: 2],
[partID:0, val: 3], [partID:1, val: 4], [partID:1, val: 5], [partID:1,
val: 6])<br>
            <br>
z.treeAggregate(0)(math.max(_, _), _ + _)<br>
res40: Int = 9<br>
            <br>
// Note unlike normal aggregrate. Tree aggregate does not apply the initial value for the second reduce<br>
// This example returns 11 since the initial value is 5<br>
// reduce of partition 0 will be max(5, 1, 2, 3) = 5<br>
// reduce of partition 1 will be max(4, 5, 6) = 6<br>
// final reduce across partitions will be 5 + 6 = 11<br>
// note the final reduce does not include the initial value<br>
z.treeAggregate(5)(math.max(_, _), _ + _)<br>
res42: Int = 11</td>
          </tr>
        </tbody>
      </table>
      <br>
      <br>
      <hr style="width: 100%; height: 2px;"><br>
      <a name="treeReduce"></a><br>
      <br>
      <br>

      <big><big><span style="font-weight: bold;">treeReduce</span></big></big><br>


      <br>
Works like reduce except reduces the elements of the RDD in a multi-level tree pattern.<br>


      <br>


      <br>


      <span style="font-weight: bold;">Listing Variants<br>
      </span><br>


      
      <div style="margin-left: 40px;">def&nbsp; treeReduce(f: (T, T) &#8658; T, depth: Int = 2): T<br>
      </div>


      <br>


      <span style="font-weight: bold;">Example</span><br>
      <br>
      <table style="text-align: left; width: 753px; margin-left: 40px; height: 43px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top;">val z = sc.parallelize(List(1,2,3,4,5,6), 2)<br>
z.treeReduce(_+_)<br>
res49: Int = 21<br>
            </td>
          </tr>
        </tbody>
      </table>
<br>
      <br>
      <hr style="width: 100%; height: 2px;"><br>
      <a name="union"></a><br>
      <br>
      <big><big><span style="font-weight: bold;">union, ++</span></big></big><br>
      <br>
Performs the standard set operation: A union B<br>
      <br>
      <br>
      <span style="font-weight: bold;">Listing Variants<br>
      </span><br>
      <div style="margin-left: 40px;">def ++(other: RDD[T]): RDD[T]<br>
def union(other: RDD[T]): RDD[T]<br>
      </div>
      <br>
      <span style="font-weight: bold;">Example</span><br>
      <br>
      <div style="margin-left: 40px;">
      <table style="text-align: left; width: 586px; height: 54px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top; background-color: rgb(242, 242, 242);">val
a = sc.parallelize(1 to 3, 1)<br>
val b = sc.parallelize(5 to 7, 1)<br>
(a ++ b).collect<br>
res0: Array[Int] = Array(1, 2, 3, 5, 6, 7)</td>
          </tr>
        </tbody>
      </table>
      </div>
      <br>
      <br>
      <hr style="width: 100%; height: 2px;"><br>
      <a name="unpersist"></a><br>
      <br>
      <big><big><span style="font-weight: bold;">unpersist</span></big></big><br>
      <br>
Dematerializes the RDD <span style="font-style: italic;">(i.e. Erases
all data items from hard-disk and memory)</span>.
However, the RDD object remains. If it is referenced in a computation,
Spark will regenerate it automatically using the stored dependency
graph.<br>
      <br>
      <br>
      <span style="font-weight: bold;">Listing Variants<br>
      </span><br>
      <div style="margin-left: 40px;">def unpersist(blocking: Boolean =
true): RDD[T]<br>
      </div>
      <br>
      <span style="font-weight: bold;">Example</span><br>
      <br>
      <div style="margin-left: 40px;">
      <table style="text-align: left; width: 586px; height: 54px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top; background-color: rgb(242, 242, 242);">val
y = sc.parallelize(1 to 10, 10)<br>
val z = (y++y)<br>
z.collect<br>
z.unpersist(true)<br>
14/04/19 03:04:57 INFO UnionRDD: Removing RDD 22 from persistence list<br>
14/04/19 03:04:57 INFO BlockManager: Removing RDD 22</td>
          </tr>
        </tbody>
      </table>
      </div>
      <br>
      <br>
      <hr style="width: 100%; height: 2px;"><br>
      <a name="values"></a><br>
      <br>
      <big><big><span style="font-weight: bold;">values</span></big></big><br>
      <br>
Extracts the values from all contained tuples and returns them in a new
RDD.<br>
      <br>
      <br>
      <span style="font-weight: bold;">Listing Variants<br>
      </span><br>
      <div style="margin-left: 40px;">def values: RDD[V]<br>
      </div>
      <br>
      <span style="font-weight: bold;">Example</span><br>
      <br>
      <div style="margin-left: 40px;">
      <table style="text-align: left; width: 586px; height: 54px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top; background-color: rgb(242, 242, 242);">val
a = sc.parallelize(List("dog", "tiger", "lion", "cat", "panther",
"eagle"), 2)<br>
val b = a.map(x =&gt; (x.length, x))<br>
b.values.collect<br>
res3: Array[String] = Array(dog, tiger, lion, cat, panther, eagle)</td>
          </tr>
        </tbody>
      </table>
      </div>
      <br>
      <br>
      <hr style="width: 100%; height: 2px;"><br>
      <a name="variance"></a><br>
      <br>
      <br>
      <big><big><span style="font-weight: bold;">variance <small>[Double]</small>,
sampleVariance <small>[Double]</small></span></big></big><br>
      <br>
Calls stats and extracts either <span style="font-style: italic;">variance</span>-component
or corrected <span style="font-style: italic;">sampleVariance</span>-component.<br>
      <br>
      <span style="font-weight: bold;">Listing Variants<br>
      </span><br>
      <div style="margin-left: 40px;">def variance(): Double<br>
def sampleVariance(): Double<br>
      </div>
      <br>
      <span style="font-weight: bold;">Example</span><br>
      <br>
      <div style="margin-left: 40px;">
      <table style="text-align: left; width: 586px; height: 54px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top; background-color: rgb(242, 242, 242);">val
a = sc.parallelize(List(9.1, 1.0, 1.2, 2.1, 1.3, 5.0, 2.0, 2.1, 7.4,
7.5, 7.6, 8.8, 10.0, 8.9, 5.5), 3)<br>
a.variance<br>
res70: Double = 10.605333333333332<br>
            <br>
val x = sc.parallelize(List(1.0, 2.0, 3.0, 5.0, 20.0, 19.02, 19.29,
11.09, 21.0), 2)<br>
x.variance<br>
res14: Double = 66.04584444444443<br>
            <br>
x.sampleVariance<br>
res13: Double = 74.30157499999999</td>
          </tr>
        </tbody>
      </table>
      </div>
      <br>
      <br>
      <hr style="width: 100%; height: 2px;"><br>
      <a name="zip"></a><br>
      <br>
      <big><big><span style="font-weight: bold;">zip</span></big></big><br>
      <br>
Joins two RDDs by combining the i-th of either partition with each
other. The resulting RDD will consist of two-component tuples which are
interpreted as key-value pairs by the methods provided by the
PairRDDFunctions extension.<br>
      <br>
      <span style="font-weight: bold;">Listing Variants<br>
      </span><br>
      <div style="margin-left: 40px;">def zip[U: ClassTag](other:
RDD[U]): RDD[(T, U)]<br>
      </div>
      <br>
      <span style="font-weight: bold;">Example</span><br>
      <br>
      <div style="margin-left: 40px;">
      <table style="text-align: left; width: 586px; height: 54px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top; background-color: rgb(242, 242, 242);">val
a = sc.parallelize(1 to 100, 3)<br>
val b = sc.parallelize(101 to 200, 3)<br>
a.zip(b).collect<br>
res1: Array[(Int, Int)] = Array((1,101), (2,102), (3,103), (4,104),
(5,105), (6,106), (7,107), (8,108), (9,109), (10,110), (11,111),
(12,112), (13,113), (14,114), (15,115), (16,116), (17,117), (18,118),
(19,119), (20,120), (21,121), (22,122), (23,123), (24,124), (25,125),
(26,126), (27,127), (28,128), (29,129), (30,130), (31,131), (32,132),
(33,133), (34,134), (35,135), (36,136), (37,137), (38,138), (39,139),
(40,140), (41,141), (42,142), (43,143), (44,144), (45,145), (46,146),
(47,147), (48,148), (49,149), (50,150), (51,151), (52,152), (53,153),
(54,154), (55,155), (56,156), (57,157), (58,158), (59,159), (60,160),
(61,161), (62,162), (63,163), (64,164), (65,165), (66,166), (67,167),
(68,168), (69,169), (70,170), (71,171), (72,172), (73,173), (74,174),
(75,175), (76,176), (77,177), (78,...<br>
            <br>
val a = sc.parallelize(1 to 100, 3)<br>
val b = sc.parallelize(101 to 200, 3)<br>
val c = sc.parallelize(201 to 300, 3)<br>
a.zip(b).zip(c).map((x) =&gt; (x._1._1, x._1._2, x._2 )).collect<br>
res12: Array[(Int, Int, Int)] = Array((1,101,201), (2,102,202),
(3,103,203), (4,104,204), (5,105,205), (6,106,206), (7,107,207),
(8,108,208), (9,109,209), (10,110,210), (11,111,211), (12,112,212),
(13,113,213), (14,114,214), (15,115,215), (16,116,216), (17,117,217),
(18,118,218), (19,119,219), (20,120,220), (21,121,221), (22,122,222),
(23,123,223), (24,124,224), (25,125,225), (26,126,226), (27,127,227),
(28,128,228), (29,129,229), (30,130,230), (31,131,231), (32,132,232),
(33,133,233), (34,134,234), (35,135,235), (36,136,236), (37,137,237),
(38,138,238), (39,139,239), (40,140,240), (41,141,241), (42,142,242),
(43,143,243), (44,144,244), (45,145,245), (46,146,246), (47,147,247),
(48,148,248), (49,149,249), (50,150,250), (51,151,251), (52,152,252),
(53,153,253), (54,154,254), (55,155,255)...</td>
          </tr>
        </tbody>
      </table>
      </div>
      <br>
      <br>
      <hr style="width: 100%; height: 2px;"><br>
      <a name="zipPartitions"></a><br>
      <br>
      <big><big><span style="font-weight: bold;">zipParititions</span></big></big><br>
      <br>
Similar to <span style="font-style: italic;">zip</span>. But provides
more control over the zipping process.<br>
      <br>
      <span style="font-weight: bold;">Listing Variants<br>
      </span><br>
      <div style="margin-left: 40px;">def zipPartitions[B: ClassTag, V:
ClassTag](rdd2: RDD[B])(f: (Iterator[T], Iterator[B]) =&gt;
Iterator[V]): RDD[V]<br>
def zipPartitions[B: ClassTag, V: ClassTag](rdd2: RDD[B],
preservesPartitioning: Boolean)(f: (Iterator[T], Iterator[B]) =&gt;
Iterator[V]): RDD[V]<br>
def zipPartitions[B: ClassTag, C: ClassTag, V: ClassTag](rdd2: RDD[B],
rdd3: RDD[C])(f: (Iterator[T], Iterator[B], Iterator[C]) =&gt;
Iterator[V]): RDD[V]<br>
def zipPartitions[B: ClassTag, C: ClassTag, V: ClassTag](rdd2: RDD[B],
rdd3: RDD[C], preservesPartitioning: Boolean)(f: (Iterator[T],
Iterator[B], Iterator[C]) =&gt; Iterator[V]): RDD[V]<br>
def zipPartitions[B: ClassTag, C: ClassTag, D: ClassTag, V:
ClassTag](rdd2: RDD[B], rdd3: RDD[C], rdd4: RDD[D])(f: (Iterator[T],
Iterator[B], Iterator[C], Iterator[D]) =&gt; Iterator[V]): RDD[V]<br>
def zipPartitions[B: ClassTag, C: ClassTag, D: ClassTag, V:
ClassTag](rdd2: RDD[B], rdd3: RDD[C], rdd4: RDD[D],
preservesPartitioning: Boolean)(f: (Iterator[T], Iterator[B],
Iterator[C], Iterator[D]) =&gt; Iterator[V]): RDD[V]<br>
      </div>
      <br>
      <span style="font-weight: bold;">Example</span><br>
      <br>
      <div style="margin-left: 40px;">
      <table style="text-align: left; width: 586px; height: 54px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top; background-color: rgb(242, 242, 242);">val
a = sc.parallelize(0 to 9, 3)<br>
val b = sc.parallelize(10 to 19, 3)<br>
val c = sc.parallelize(100 to 109, 3)<br>
def myfunc(aiter: Iterator[Int], biter: Iterator[Int], citer:
Iterator[Int]): Iterator[String] =<br>
{<br>
&nbsp; var res = List[String]()<br>
&nbsp; while (aiter.hasNext &amp;&amp; biter.hasNext &amp;&amp;
citer.hasNext)<br>
&nbsp; {<br>
&nbsp;&nbsp;&nbsp; val x = aiter.next + " " + biter.next + " " +
citer.next<br>
&nbsp;&nbsp;&nbsp; res ::= x<br>
&nbsp; }<br>
&nbsp; res.iterator<br>
}<br>
a.zipPartitions(b, c)(myfunc).collect<br>
res50: Array[String] = Array(2 12 102, 1 11 101, 0 10 100, 5 15 105, 4
14 104, 3 13 103, 9 19 109, 8 18 108, 7 17 107, 6 16 106)</td>
          </tr>
        </tbody>
      </table>
      <br>
      </div>
      <br>
      <hr style="width: 100%; height: 2px;"><a name="zipWithIndex"></a><br>
      <br>
      <big><big><span style="font-weight: bold;">zipWithIndex</span></big></big><br>
      <br>
Zips the elements of the RDD with its element indexes. The indexes
start from 0. If the RDD is spread across multiple partitions then a
spark Job is started to perform this operation.<br>
      <br>
      <span style="font-weight: bold;">Listing Variants<br>
      </span><br>
      <div style="margin-left: 40px;">def zipWithIndex(): RDD[(T, Long)]<br>
      </div>
      <br>
      <span style="font-weight: bold;">Example</span><br>
      <br>
      <table style="text-align: left; width: 629px; height: 28px; margin-left: 40px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top;">val z =
sc.parallelize(Array("A", "B", "C", "D"))<br>
val r = z.zipWithIndex<br>
res110: Array[(String, Long)] = Array((A,0), (B,1), (C,2), (D,3))<br>
            <br>
val z = sc.parallelize(100 to 120, 5)<br>
val r = z.zipWithIndex<br>
r.collect<br>res11:
Array[(Int, Long)] = Array((100,0), (101,1), (102,2), (103,3), (104,4),
(105,5), (106,6), (107,7), (108,8), (109,9), (110,10), (111,11),
(112,12), (113,13), (114,14), (115,15), (116,16), (117,17), (118,18),
(119,19), (120,20))<br>
            <br>
            </td>
          </tr>
        </tbody>
      </table>
      <br>
      <br>
      <hr style="width: 100%; height: 2px;"><a name="zipWithUniqueId"></a><br>
      <br>
      <big><big><span style="font-weight: bold;">zipWithUniqueId</span></big></big><br>
      <br>
This is different from zipWithIndex since just gives a unique id to
each data element but the ids may not match the index number of the
data element. This operation does not start a spark job even if the RDD
is spread across multiple partitions.<br>
Compare the results of the example below with that of the 2nd example
of zipWithIndex. You should be able to see the difference.<br>
      <br>
      <span style="font-weight: bold;">Listing Variants<br>
      </span><br>
      <div style="margin-left: 40px;">def zipWithUniqueId(): RDD[(T,
Long)]<br>
      </div>
      <br>
      <span style="font-weight: bold;">Example</span><br>
      <br>
      <table style="text-align: left; width: 672px; margin-left: 40px; height: 28px;" border="1" cellpadding="2" cellspacing="2">
        <tbody>
          <tr>
            <td style="vertical-align: top;">val z = sc.parallelize(100
to 120, 5)<br>
val r = z.zipWithUniqueId<br>
r.collect<br>
            <br>res12:
Array[(Int, Long)] = Array((100,0), (101,5), (102,10), (103,15),
(104,1), (105,6), (106,11), (107,16), (108,2), (109,7), (110,12),
(111,17), (112,3), (113,8), (114,13), (115,18), (116,4), (117,9),
(118,14), (119,19), (120,24))<br>
            </td>
          </tr>
        </tbody>
      </table>
      <br>
      <br>
      </td>
    </tr>
  </tbody>
</table>

<!-- End of StatCounter Code for Default Guide -->
</body></html>